{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb, gc, optuna, shutil\n",
    "import torch, json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader\n",
    "from rl import make_transition, make_df, make_transition_test, Sampler, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n",
      "True\n",
      "1\n",
      "12.1\n",
      "NVIDIA GeForce RTX 4080\n",
      "학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('processed/train_id.csv',index_col=0)\n",
    "valid_id = pd.read_csv('processed/val_id.csv',index_col=0)\n",
    "test_id = pd.read_csv('processed/test_id.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, latent_dim=16, hidden_size=128):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(state_dim + action_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_size, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_size, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(state_dim + latent_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, action_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, s, a=None):\n",
    "        if a is not None:\n",
    "            if a.dim() == 2 and a.shape[1] == 1:\n",
    "                a = a.squeeze(1)\n",
    "            batch_size = s.size(0)\n",
    "            action_dim = self.decoder[-1].out_features\n",
    "            a_onehot = F.one_hot(a, num_classes=action_dim).float()\n",
    "            enc_input = torch.cat([s, a_onehot], dim=1)\n",
    "            h = self.encoder(enc_input)\n",
    "            mu = self.fc_mu(h)\n",
    "            logvar = self.fc_logvar(h)\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            z = mu + eps * std\n",
    "            dec_input = torch.cat([s, z], dim=1)\n",
    "            logits = self.decoder(dec_input)\n",
    "            return logits, mu, logvar\n",
    "        else:\n",
    "            raise NotImplementedError(\"Use sample_actions method to generate actions without a label.\")\n",
    "\n",
    "    def sample_actions(self, s, num_samples):\n",
    "        batch_size = s.size(0)\n",
    "        latent_dim = self.fc_mu.out_features\n",
    "        s_repeat = s.unsqueeze(1).repeat(1, num_samples, 1)\n",
    "        s_repeat = s_repeat.view(batch_size * num_samples, -1)\n",
    "        z = torch.randn(batch_size * num_samples, latent_dim, device=s.device)\n",
    "        dec_in = torch.cat([s_repeat, z], dim=1)\n",
    "        logits = self.decoder(dec_in)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        a_samples = torch.multinomial(probs, 1)\n",
    "        return a_samples.view(batch_size, num_samples)\n",
    "\n",
    "def vae_loss(logits, a, mu, logvar):\n",
    "    recon_loss = F.cross_entropy(logits, a, reduction='mean')\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + 0.5 * kld\n",
    "\n",
    "class Perturbation(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size=128):\n",
    "        super(Perturbation, self).__init__()\n",
    "        self.action_dim = action_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim + action_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, s, a):\n",
    "        if a.dim() == 2 and a.shape[1] == 1:\n",
    "            a = a.squeeze(1)\n",
    "        a_onehot = F.one_hot(a, num_classes=self.action_dim).float()\n",
    "        x = torch.cat([s, a_onehot], dim=1)\n",
    "        return self.net(x)\n",
    "\n",
    "def pretrain_vae(train_data, vae, vae_lr=1e-3, vae_epochs=10, batch_size=256):\n",
    "    optimizer = optim.Adam(vae.parameters(), lr=vae_lr)\n",
    "    loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    vae.train()\n",
    "    for ep in range(vae_epochs):\n",
    "        total_loss = 0\n",
    "        for s, a, r, s2, t in loader:\n",
    "            s, a = s.to(device), a.to(device)\n",
    "            if a.dim() == 2 and a.shape[1] == 1:\n",
    "                a = a.squeeze(1)\n",
    "            a = a.long() - 1\n",
    "            logits, mu, logvar = vae(s, a)\n",
    "            loss = vae_loss(logits, a, mu, logvar)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[VAE pretrain epoch {ep+1}/{vae_epochs}] loss={total_loss/len(loader):.4f}\")\n",
    "    return vae\n",
    "\n",
    "def load_best_vae_perturbation(study, obs_dim, nb_actions, path):\n",
    "    best_trial = study.best_trial\n",
    "    best_trial_number = best_trial.number + 1\n",
    "    vae_path = f\"{path}/vae_pretrained_{best_trial_number}.pth\"\n",
    "    perturb_path = f\"{path}/perturb_pretrained_{best_trial_number}.pth\"\n",
    "    vae = VAE(state_dim=obs_dim, action_dim=nb_actions, latent_dim=best_trial.params['bcq_latent_dim'],\n",
    "              hidden_size=best_trial.params['bcq_hidden_size']).to(device)\n",
    "    perturbation = Perturbation(state_dim=obs_dim, action_dim=nb_actions,\n",
    "                                hidden_size=best_trial.params['bcq_hidden_size']).to(device)\n",
    "    vae.load_state_dict(torch.load(vae_path))\n",
    "    perturbation.load_state_dict(torch.load(perturb_path))\n",
    "    print(f\"Loaded best VAE and Perturbation from trial {best_trial_number}\")\n",
    "    return vae, perturbation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_vae(trial, train_data, val_data, path):\n",
    "    latent_dim = trial.suggest_int('bcq_latent_dim', 16, 32, step=8)\n",
    "    hidden_size = trial.suggest_categorical('bcq_hidden_size', [32, 64, 128])\n",
    "    vae_lr = trial.suggest_float('vae_lr', 1e-4, 5e-3, log=True)\n",
    "    vae_epochs = trial.suggest_int('bcq_pretrain_epochs', 5, 15, step=5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])\n",
    "\n",
    "    obs_dim = train_data.tensors[0].shape[1]\n",
    "    nb_actions = int(max(train_data.tensors[1]))\n",
    "\n",
    "    vae = VAE(state_dim=obs_dim, action_dim=nb_actions, latent_dim=latent_dim, hidden_size=hidden_size).to(device)\n",
    "    perturbation = Perturbation(state_dim=obs_dim, action_dim=nb_actions, hidden_size=hidden_size).to(device)\n",
    "\n",
    "    vae = pretrain_vae(train_data, vae, vae_lr=vae_lr, vae_epochs=vae_epochs, batch_size=batch_size)\n",
    "\n",
    "    vae.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for s, a, _, _, _ in DataLoader(val_data, batch_size=batch_size, num_workers=4, pin_memory=True):\n",
    "            s, a = s.to(device), a.to(device)\n",
    "\n",
    "            if a.dim() == 2 and a.shape[1] == 1:\n",
    "                a = a.squeeze(1)\n",
    "            a = a.long() - 1\n",
    "\n",
    "            logits, mu, logvar = vae(s, a)\n",
    "            loss = vae_loss(logits, a, mu, logvar)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_data)\n",
    "    print(f\"[Evaluation] VAE Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    torch.save(vae.state_dict(), f\"{path}/vae_pretrained_{trial.number+1}.pth\")\n",
    "    torch.save(perturbation.state_dict(), f\"{path}/perturb_pretrained_{trial.number+1}.pth\")\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectile_loss(advantage, tau):\n",
    "    positive_mask = (advantage > 0).float()\n",
    "    weight = tau * positive_mask + (1.0 - tau) * (1.0 - positive_mask)\n",
    "    return (weight * (advantage ** 2)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    batch_size, lr, lr_decay, lr_epoch, ns, epochs, update_freq,\n",
    "    mlp_size, mlp_num_layers, activation_type,\n",
    "    algorithm,\n",
    "    version,\n",
    "    vae,\n",
    "    perturbation,\n",
    "    path,\n",
    "    train_data, val_data, val_transition,\n",
    "    alpha=0,\n",
    "    bcq_num_samples=0,\n",
    "    bcq_threshold=0.0,\n",
    "    re_score_lambda=0.0,\n",
    "    tau=0.7,\n",
    "    trial=None,\n",
    "    device=device\n",
    "):\n",
    "    def clamping(data, version):\n",
    "        if version == '_negative':\n",
    "            data_clamped = torch.clamp(data, min=-1.0, max=0.0)\n",
    "        elif version == '_positive':\n",
    "            data_clamped = torch.clamp(data, min=0.0, max=1.0)\n",
    "        else:\n",
    "            data_clamped = torch.clamp(data, min=-1.0, max=1.0)\n",
    "        return data_clamped\n",
    "\n",
    "    d_f = 1.0\n",
    "    num_workers = 4\n",
    "    patience = 10\n",
    "    best_loss = float('inf')\n",
    "    best_auroc_p_gat = 0.0\n",
    "    best_auroc_p_med = 0.0\n",
    "    no_improve_count = 0\n",
    "\n",
    "    valid_auroc_gat, valid_auroc_med, valid_auroc_min, valid_auroc_max = [], [], [], []\n",
    "    valid_auroc_p_gat, valid_auroc_p_med, valid_auroc_p_min, valid_auroc_p_max = [], [], [], []\n",
    "    train_losses, valid_losses = [], []\n",
    "\n",
    "    obs_dim = train_data.tensors[0].shape[1]\n",
    "    nb_actions = int(max(train_data.tensors[1]))\n",
    "\n",
    "    network = Model(\n",
    "        obs_dim=obs_dim,\n",
    "        nb_actions=nb_actions,\n",
    "        mlp_size=mlp_size,\n",
    "        mlp_num_layers=mlp_num_layers,\n",
    "        activation_type=activation_type\n",
    "    ).to(device)\n",
    "\n",
    "    target_network = Model(\n",
    "        obs_dim=obs_dim,\n",
    "        nb_actions=nb_actions,\n",
    "        mlp_size=mlp_size,\n",
    "        mlp_num_layers=mlp_num_layers,\n",
    "        activation_type=activation_type\n",
    "    ).to(device)\n",
    "    target_network.load_state_dict(network.state_dict())\n",
    "\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=lr_decay)\n",
    "\n",
    "    if algorithm == '_bcq':\n",
    "        optimizer = optim.Adam(\n",
    "            list(network.parameters()) + list(perturbation.parameters()),\n",
    "            lr=lr\n",
    "        )\n",
    "\n",
    "    if algorithm == '_iql':\n",
    "        value_network = Model(\n",
    "            obs_dim=obs_dim,\n",
    "            nb_actions=1,\n",
    "            mlp_size=mlp_size,\n",
    "            mlp_num_layers=mlp_num_layers,\n",
    "            activation_type=activation_type\n",
    "        ).to(device)\n",
    "\n",
    "        target_value_network = Model(\n",
    "            obs_dim=obs_dim,\n",
    "            nb_actions=1,\n",
    "            mlp_size=mlp_size,\n",
    "            mlp_num_layers=mlp_num_layers,\n",
    "            activation_type=activation_type\n",
    "        ).to(device)\n",
    "        target_value_network.load_state_dict(value_network.state_dict())\n",
    "\n",
    "        value_optimizer = optim.Adam(value_network.parameters(), lr=lr)\n",
    "        value_scheduler = ExponentialLR(value_optimizer, gamma=lr_decay)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_sampler=Sampler(train_data, batch_size, version, ns),\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(val_data, batch_size=4096, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        network.train()\n",
    "        if perturbation is not None:\n",
    "            perturbation.train()\n",
    "        if algorithm == '_iql':\n",
    "            value_network.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for s, a, r, s2, t in train_loader:\n",
    "            s, a, r, s2, t = s.to(device), a.to(device), r.to(device), s2.to(device), t.to(device)\n",
    "            a = a.long() - 1\n",
    "            r_clamped = clamping(r, version)\n",
    "\n",
    "            if algorithm == '_iql':\n",
    "                q_values = network(s)\n",
    "                q_pred = q_values.gather(1, a).squeeze(1)\n",
    "                v_pred = value_network(s).squeeze(1)\n",
    "                adv = q_pred.detach() - v_pred\n",
    "                value_loss = expectile_loss(adv, tau)\n",
    "\n",
    "                value_optimizer.zero_grad()\n",
    "                value_loss.backward()\n",
    "                value_optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    v_next = target_value_network(s2).squeeze(1)\n",
    "                v_clamped = clamping(v_next, version)\n",
    "\n",
    "                bellman_target = r_clamped + d_f * v_clamped * (1. - t)\n",
    "                q_pred = q_values.gather(1, a).squeeze(1)\n",
    "                q_loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                q_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss = value_loss.item() + q_loss.item()\n",
    "                train_loss += total_loss\n",
    "\n",
    "            else:\n",
    "                q_values = network(s)\n",
    "                q_pred = q_values.gather(1, a).squeeze(1)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    q2_tgt = target_network(s2)\n",
    "\n",
    "                    if algorithm == '_dqn':\n",
    "                        max_actions = torch.max(q2_tgt, dim=1)[1].unsqueeze(1)\n",
    "                        q2_max = q2_tgt.gather(1, max_actions).squeeze()\n",
    "\n",
    "                    elif algorithm == '_bcq':\n",
    "                        candidates = vae.sample_actions(s2, num_samples=bcq_num_samples)\n",
    "                        B = s2.size(0)\n",
    "                        q2_rep = q2_tgt.unsqueeze(1).repeat(1, bcq_num_samples, 1).view(B * bcq_num_samples, nb_actions)\n",
    "                        cand_flat = candidates.view(B * bcq_num_samples)\n",
    "                        q2_for_cand = q2_rep.gather(1, cand_flat.unsqueeze(1)).squeeze(1).view(B, bcq_num_samples)\n",
    "\n",
    "                        re_score = torch.zeros_like(q2_for_cand)\n",
    "                        if perturbation is not None:\n",
    "                            s_expand = s2.unsqueeze(1).repeat(1, bcq_num_samples, 1).view(B * bcq_num_samples, -1)\n",
    "                            pert_scores = perturbation(s_expand, cand_flat).view(B, bcq_num_samples)\n",
    "                            re_score = re_score_lambda * pert_scores\n",
    "\n",
    "                        total_score = q2_for_cand + re_score\n",
    "                        best_actions = []\n",
    "                        for i in range(B):\n",
    "                            valid_mask = (q2_for_cand[i] >= bcq_threshold)\n",
    "                            valid_indices = torch.where(valid_mask)[0]\n",
    "                            if len(valid_indices) == 0:\n",
    "                                idx = torch.argmax(q2_for_cand[i])\n",
    "                            else:\n",
    "                                sub_score = total_score[i][valid_indices]\n",
    "                                idx_local = torch.argmax(sub_score)\n",
    "                                idx = valid_indices[idx_local]\n",
    "                            best_act = candidates[i, idx]\n",
    "                            best_actions.append(best_act.item())\n",
    "\n",
    "                        best_actions = torch.tensor(best_actions, device=s2.device, dtype=torch.long)\n",
    "                        q2_max = q2_tgt.gather(1, best_actions.unsqueeze(1)).squeeze()\n",
    "\n",
    "                    else:\n",
    "                        q2_net = network(s2)\n",
    "                        max_actions = torch.max(q2_net, dim=1)[1].unsqueeze(1)\n",
    "                        q2_max = q2_tgt.gather(1, max_actions).squeeze()\n",
    "\n",
    "                q2_max_clamped = clamping(q2_max, version)\n",
    "                bellman_target = r_clamped + d_f * q2_max_clamped * (1 - t)\n",
    "                td_loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "\n",
    "                if algorithm in ['_dqn', '_ddqn', '_bcq']:\n",
    "                    loss = td_loss\n",
    "                elif algorithm == '_cql':\n",
    "                    logsumexp_q = torch.logsumexp(q_values, dim=1)\n",
    "                    cql_term = (logsumexp_q - q_pred).mean()\n",
    "                    loss = td_loss + alpha * cql_term\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "        network.eval()\n",
    "        if perturbation is not None:\n",
    "            perturbation.eval()\n",
    "        if algorithm == '_iql':\n",
    "            value_network.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0.0\n",
    "            for s, a, r, s2, t in val_loader:\n",
    "                s, a, r, s2, t = s.to(device), a.to(device), r.to(device), s2.to(device), t.to(device)\n",
    "                a = a.long() - 1\n",
    "                r_clamped = clamping(r, version)\n",
    "                q_values = network(s)\n",
    "                q_pred = q_values.gather(1, a).squeeze()\n",
    "\n",
    "                if algorithm == '_iql':\n",
    "                    v_next = target_value_network(s2).squeeze(1)\n",
    "                    v_clamped = clamping(v_next, version)\n",
    "                    bellman_target = r_clamped + d_f * v_clamped * (1. - t)\n",
    "                    loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "                    valid_loss += loss.item()\n",
    "                else:\n",
    "                    q2_tgt = target_network(s2)\n",
    "                    if algorithm == '_dqn':\n",
    "                        max_actions = torch.max(q2_tgt, dim=1)[1].unsqueeze(1)\n",
    "                        q2_max = q2_tgt.gather(1, max_actions).squeeze()\n",
    "                    elif algorithm == '_bcq':\n",
    "                        candidates = vae.sample_actions(s2, bcq_num_samples)\n",
    "                        B = s2.size(0)\n",
    "                        q2_rep = q2_tgt.unsqueeze(1).repeat(1, bcq_num_samples, 1).view(B * bcq_num_samples, nb_actions)\n",
    "                        cand_flat = candidates.view(B * bcq_num_samples)\n",
    "                        q2_for_cand = q2_rep.gather(1, cand_flat.unsqueeze(1)).squeeze(1).view(B, bcq_num_samples)\n",
    "                        re_score = torch.zeros_like(q2_for_cand)\n",
    "                        if perturbation is not None:\n",
    "                            s_expand = s2.unsqueeze(1).repeat(1, bcq_num_samples, 1).view(B * bcq_num_samples, -1)\n",
    "                            pert_scores = perturbation(s_expand, cand_flat).view(B, bcq_num_samples)\n",
    "                            re_score = re_score_lambda * pert_scores\n",
    "                        total_score = q2_for_cand + re_score\n",
    "                        best_actions = []\n",
    "                        for i in range(B):\n",
    "                            valid_mask = (q2_for_cand[i] >= bcq_threshold)\n",
    "                            valid_indices = torch.where(valid_mask)[0]\n",
    "                            if len(valid_indices) == 0:\n",
    "                                idx = torch.argmax(q2_for_cand[i])\n",
    "                            else:\n",
    "                                sub_score = total_score[i][valid_indices]\n",
    "                                idx_local = torch.argmax(sub_score)\n",
    "                                idx = valid_indices[idx_local]\n",
    "                            best_act = candidates[i, idx]\n",
    "                            best_actions.append(best_act.item())\n",
    "                        best_actions = torch.tensor(best_actions, device=s2.device, dtype=torch.long)\n",
    "                        q2_max = q2_tgt.gather(1, best_actions.unsqueeze(1)).squeeze()\n",
    "                    else:\n",
    "                        q2_net = network(s2)\n",
    "                        max_actions = torch.max(q2_net, dim=1)[1].unsqueeze(1)\n",
    "                        q2_max = q2_tgt.gather(1, max_actions).squeeze()\n",
    "\n",
    "                    q2_max_clamped = clamping(q2_max, version)\n",
    "                    bellman_target = r_clamped + d_f * q2_max_clamped * (1 - t)\n",
    "                    loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "                    valid_loss += loss.item()\n",
    "\n",
    "            q_value_list, reward_list, patient_list, action_list = [], [], [], []\n",
    "            for s, a, r, rp in val_transition:\n",
    "                s, a = s.to(device), a.to(device)\n",
    "                a = a.long() - 1\n",
    "                q = network(s)\n",
    "                r_clamped = clamping(r, version)\n",
    "                rp_clamped = clamping(rp, version)\n",
    "                q_clamped = clamping(q, version)\n",
    "                q_value_list.append(q_clamped.detach().cpu().numpy())\n",
    "                reward_list.append(r_clamped.detach().cpu().numpy())\n",
    "                patient_list.append(rp_clamped.detach().cpu().numpy())\n",
    "                action_list.append(a.detach().cpu().numpy())\n",
    "\n",
    "            action_space = np.concatenate(action_list, axis=0)\n",
    "            q_value = np.concatenate(q_value_list, axis=0)\n",
    "            reward = np.concatenate(reward_list, axis=0)\n",
    "            patient = np.concatenate(patient_list, axis=0)\n",
    "\n",
    "            q_max = np.max(q_value, axis=1)\n",
    "            q_min = np.min(q_value, axis=1)\n",
    "            q_median = np.median(q_value, axis=1)\n",
    "            q_gather = q_value[np.arange(q_value.shape[0]), action_space]\n",
    "\n",
    "            auroc_p_max = roc_auc_score(patient, q_max)\n",
    "            auroc_p_min = roc_auc_score(patient, q_min)\n",
    "            auroc_p_med = roc_auc_score(patient, q_median)\n",
    "            auroc_p_gat = roc_auc_score(patient, q_gather)\n",
    "\n",
    "            valid_auroc_p_gat.append(auroc_p_gat)\n",
    "            valid_auroc_p_med.append(auroc_p_med)\n",
    "            valid_auroc_p_min.append(auroc_p_min)\n",
    "            valid_auroc_p_max.append(auroc_p_max)\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "            if version != '_both':\n",
    "                auroc_max = roc_auc_score(reward, q_max)\n",
    "                auroc_min = roc_auc_score(reward, q_min)\n",
    "                auroc_med = roc_auc_score(reward, q_median)\n",
    "                auroc_gat = roc_auc_score(reward, q_gather)\n",
    "                valid_auroc_gat.append(auroc_gat)\n",
    "                valid_auroc_med.append(auroc_med)\n",
    "                valid_auroc_min.append(auroc_min)\n",
    "                valid_auroc_max.append(auroc_max)\n",
    "                wandb.log({\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss,\n",
    "                    'reward_max': auroc_max,\n",
    "                    'reward_min': auroc_min,\n",
    "                    'reward_median': auroc_med,\n",
    "                    'reward_gather': auroc_gat,\n",
    "                    'patient_max': auroc_p_max,\n",
    "                    'patient_min': auroc_p_min,\n",
    "                    'patient_median': auroc_p_med,\n",
    "                    'patient_gather': auroc_p_gat\n",
    "                })\n",
    "            else:\n",
    "                wandb.log({\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss,\n",
    "                    'patient_max': auroc_p_max,\n",
    "                    'patient_min': auroc_p_min,\n",
    "                    'patient_median': auroc_p_med,\n",
    "                    'patient_gather': auroc_p_gat\n",
    "                })\n",
    "\n",
    "        if (auroc_p_gat > best_auroc_p_gat) & (auroc_p_med > best_auroc_p_med):\n",
    "            best_auroc_p_gat = auroc_p_gat\n",
    "            best_auroc_p_med = auroc_p_med\n",
    "            no_improve_count = 0\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        torch.save(network.state_dict(), os.path.join(path, f'network_{epoch}.pth'))\n",
    "        torch.save(target_network.state_dict(), os.path.join(path, f'target_network_{epoch}.pth'))\n",
    "\n",
    "        if algorithm == '_iql':\n",
    "            torch.save(value_network.state_dict(), os.path.join(path, f'value_network_{epoch}.pth'))\n",
    "            torch.save(target_value_network.state_dict(), os.path.join(path, f'target_value_network_{epoch}.pth'))\n",
    "\n",
    "        if epoch % lr_epoch == 0:\n",
    "            scheduler.step()\n",
    "            if algorithm == '_iql':\n",
    "                value_scheduler.step()\n",
    "\n",
    "        if epoch % update_freq == 0:\n",
    "            target_network.load_state_dict(network.state_dict())\n",
    "            if algorithm == '_iql':\n",
    "                target_value_network.load_state_dict(value_network.state_dict())\n",
    "\n",
    "        if no_improve_count >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch} due to no improvement.\")\n",
    "            break\n",
    "\n",
    "        trial.report(auroc_p_gat + auroc_p_med, step=epoch)\n",
    "        if trial.should_prune():\n",
    "            metrics = []\n",
    "            if version != '_both':\n",
    "                metrics.extend(['gat', 'med', 'min', 'max'])\n",
    "            metrics.extend(['p_gat', 'p_med', 'p_min', 'p_max'])\n",
    "\n",
    "            valid_auroc_values = {}\n",
    "            if version != '_both':\n",
    "                valid_auroc_values['gat'] = valid_auroc_gat\n",
    "                valid_auroc_values['med'] = valid_auroc_med\n",
    "                valid_auroc_values['min'] = valid_auroc_min\n",
    "                valid_auroc_values['max'] = valid_auroc_max\n",
    "\n",
    "            valid_auroc_values['p_gat'] = valid_auroc_p_gat\n",
    "            valid_auroc_values['p_med'] = valid_auroc_p_med\n",
    "            valid_auroc_values['p_min'] = valid_auroc_p_min\n",
    "            valid_auroc_values['p_max'] = valid_auroc_p_max\n",
    "\n",
    "            for metric in metrics:\n",
    "                torch.save(valid_auroc_values[metric], f'{path}/valid_auroc_{metric}.pth')\n",
    "\n",
    "            torch.save(train_losses, f'{path}/train_losses.pth')\n",
    "            torch.save(valid_losses, f'{path}/valid_losses.pth')\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    metrics = []\n",
    "    if version != '_both':\n",
    "        metrics.extend(['gat', 'med', 'min', 'max'])\n",
    "    metrics.extend(['p_gat', 'p_med', 'p_min', 'p_max'])\n",
    "\n",
    "    valid_auroc_values = {}\n",
    "    if version != '_both':\n",
    "        valid_auroc_values['gat'] = valid_auroc_gat\n",
    "        valid_auroc_values['med'] = valid_auroc_med\n",
    "        valid_auroc_values['min'] = valid_auroc_min\n",
    "        valid_auroc_values['max'] = valid_auroc_max\n",
    "\n",
    "    valid_auroc_values['p_gat'] = valid_auroc_p_gat\n",
    "    valid_auroc_values['p_med'] = valid_auroc_p_med\n",
    "    valid_auroc_values['p_min'] = valid_auroc_p_min\n",
    "    valid_auroc_values['p_max'] = valid_auroc_p_max\n",
    "\n",
    "    for metric in metrics:\n",
    "        torch.save(valid_auroc_values[metric], f'{path}/valid_auroc_{metric}.pth')\n",
    "\n",
    "    torch.save(train_losses, f'{path}/train_losses.pth')\n",
    "    torch.save(valid_losses, f'{path}/valid_losses.pth')\n",
    "\n",
    "    return max([x + y for x, y in zip(valid_auroc_p_gat, valid_auroc_p_med)]) if len(valid_auroc_p_gat) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_data, val_data, val_transition, target, version, algorithm, vae, perturbation):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    config = {\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [128, 256, 512]),\n",
    "        'lr': trial.suggest_categorical('lr', [1e-4, 1e-3, 1e-2]),\n",
    "        'lr_decay': trial.suggest_categorical('lr_decay', [0.9, 0.95, 0.99]),\n",
    "        'lr_epoch': trial.suggest_categorical('lr_epoch', [1, 2, 3]),\n",
    "        'ns': trial.suggest_categorical('negative_sampling', [2, 4, 8]),\n",
    "        'epochs': trial.suggest_categorical('epochs', [200]),\n",
    "        'update_freq': trial.suggest_categorical('update_freq', [1, 2, 3]),\n",
    "        'mlp_size': trial.suggest_categorical('mlp_size', [32, 64, 128]),\n",
    "        'mlp_num_layers': trial.suggest_int('mlp_num_layers', 1, 3),\n",
    "        'activation_type': trial.suggest_categorical('activation_type', ['ReLU', 'LeakyReLU', 'Tanh']),\n",
    "        'algorithm': trial.suggest_categorical('algorithm', [algorithm]),\n",
    "        'version': trial.suggest_categorical('version', [version]),\n",
    "    }\n",
    "\n",
    "    if algorithm == '_bcq':\n",
    "        config['bcq_num_samples'] = trial.suggest_int('bcq_num_samples', 7, 9)\n",
    "        config['bcq_threshold'] = trial.suggest_float('bcq_threshold', 0.1, 0.3, step=0.1)\n",
    "        config['re_score_lambda'] = trial.suggest_float('re_score_lambda', 0.1, 0.3, step=0.1)\n",
    "\n",
    "    if algorithm == '_cql':\n",
    "        config['alpha'] = trial.suggest_categorical('alpha', [1e-4, 1e-2, 1.0])\n",
    "\n",
    "    if algorithm == '_iql':\n",
    "        config['tau'] = trial.suggest_float('tau', 0.7, 0.9, step=0.1)\n",
    "\n",
    "    result = None\n",
    "\n",
    "    try:\n",
    "        print(f\"[INFO] Starting trial {trial.number+1}\")\n",
    "        \n",
    "        if wandb.run is not None:\n",
    "            print(\"[INFO] Existing wandb run detected. Finishing it.\")\n",
    "            wandb.finish()\n",
    "        \n",
    "        wandb.init(\n",
    "            project=f'MedClap_{target}',\n",
    "            name=f'H-{algorithm}-{version}-{trial.number+1}',\n",
    "            config=config,\n",
    "            settings=wandb.Settings(init_timeout=180, start_method=\"thread\")\n",
    "        )\n",
    "        \n",
    "        print(\"[INFO] wandb initialized.\")\n",
    "\n",
    "        model_save_path = os.path.join(\n",
    "            'experiments', target.lower(), algorithm, version, f'trial_{trial.number+1}'\n",
    "        )\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        print(f\"[INFO] Model save path created: {model_save_path}\")\n",
    "\n",
    "        result = train(\n",
    "            path=model_save_path,\n",
    "            train_data=train_data,\n",
    "            val_data=val_data,\n",
    "            val_transition=val_transition,\n",
    "            vae=vae,\n",
    "            perturbation=perturbation,\n",
    "            trial=trial,\n",
    "            device=device,\n",
    "            **config\n",
    "        )\n",
    "        print(f\"[INFO] Trial {trial.number+1} finished successfully.\")\n",
    "    except optuna.TrialPruned:\n",
    "        print(f\"[INFO] Trial {trial.number+1} pruned.\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"[ERROR] Error in trial {trial.number+1}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        if wandb.run is not None:\n",
    "            wandb.finish()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.pruners import BasePruner, HyperbandPruner, ThresholdPruner\n",
    "\n",
    "class CompositePruner(BasePruner):\n",
    "    def __init__(self, pruner1, pruner2):\n",
    "        self.pruner1 = pruner1\n",
    "        self.pruner2 = pruner2\n",
    "\n",
    "    def prune(self, study, trial):\n",
    "        prune1 = self.pruner1.prune(study, trial)\n",
    "        prune2 = self.pruner2.prune(study, trial)\n",
    "        return prune1 or prune2\n",
    "\n",
    "hyperband = HyperbandPruner(min_resource=10, max_resource='auto', reduction_factor=3)\n",
    "threshold = ThresholdPruner(n_warmup_steps=10, lower=1.5)\n",
    "\n",
    "pruner = CompositePruner(hyperband, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.TPESampler(\n",
    "    n_startup_trials=20, \n",
    "    n_ei_candidates=40,      \n",
    "    multivariate=True,       \n",
    "    warn_independent_sampling=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['Dead_icu', 'Dead_hosp', 'Dead_90'] + ['AKI_rrt', 'AKI_48', 'AKI_24', 'AKI_12'] + ['Septic_shock']\n",
    "prefixes = ['dead_icu', 'dead_hosp', 'dead_90'] + ['aki_rrt', 'aki_48', 'aki_24', 'aki_12'] + ['septic_shock']\n",
    "algorithms = ['_ddqn','_cql','_iql','_bcq']\n",
    "versions = ['_negative','_positive','_both']\n",
    "base_path, n_trials, pre_train_trials = 'experiments', 100, 20\n",
    "\n",
    "vae_cache = {\n",
    "    'Dead': None,\n",
    "    'AKI': None,\n",
    "    'Septic_shock': None\n",
    "}\n",
    "perturb_cache = {\n",
    "    'Dead': None,\n",
    "    'AKI': None,\n",
    "    'Septic_shock': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for idx, target in enumerate(targets):\n",
    "\n",
    "        if 'Septic' in target : reward = 'r:reward_septic_shock'\n",
    "        elif 'Dead' in target : reward = 'r:reward_dead'\n",
    "        else : reward = 'r:reward_aki'\n",
    "\n",
    "        data = pd.read_csv(f'processed/df_{target}.csv')\n",
    "        #data[reward] = data.groupby('traj')[reward].transform(lambda x: x[:-1].tolist() + ([1] if x.iloc[-1] == 0 else [x.iloc[-1]]))\n",
    "\n",
    "        train_df, valid_df, test_df = make_df(data, reward, train_id, valid_id, test_id)\n",
    "        train_data, val_data = (make_transition(df, reward, rolling_size=1) for df in (train_df, valid_df))\n",
    "        val_transition = make_transition_test(valid_df, reward, rolling_size=1)\n",
    "            \n",
    "        for algorithm in algorithms:\n",
    "\n",
    "            path = os.path.join('experiments', prefixes[idx], algorithm)\n",
    "            shutil.rmtree(path, ignore_errors=True)\n",
    "            os.makedirs(path)\n",
    "\n",
    "            vae, perturbation = None, None\n",
    "\n",
    "            if algorithm == '_bcq':\n",
    "                if 'Dead' in target:\n",
    "                    group = 'Dead'\n",
    "                elif 'AKI' in target:\n",
    "                    group = 'AKI'\n",
    "                else:\n",
    "                    group = 'Septic_shock'\n",
    "                \n",
    "                if vae_cache[group] is None:\n",
    "                    print(f\"Training VAE for {group} group...\")\n",
    "\n",
    "                    study = optuna.create_study(direction='minimize') \n",
    "                    path = os.path.join('experiments', prefixes[idx], algorithm)\n",
    "                    study.optimize(lambda trial: objective_vae(trial, train_data, val_data, path), n_trials=pre_train_trials, n_jobs=1, gc_after_trial=True,)\n",
    "\n",
    "                    obs_dim = train_data.tensors[0].shape[1]\n",
    "                    nb_actions = int(max(train_data.tensors[1]))\n",
    "                    vae, perturbation = load_best_vae_perturbation(study, obs_dim, nb_actions, path)\n",
    "\n",
    "                    vae_cache[group] = vae\n",
    "                    perturb_cache[group] = perturbation\n",
    "                else:\n",
    "                    print(f\"Using cached VAE for {group} group.\")\n",
    "                    vae = vae_cache[group]\n",
    "                    perturbation = perturb_cache[group]\n",
    "                \n",
    "            for version in versions:\n",
    "\n",
    "                best_params_path = os.path.join('experiments', prefixes[idx], algorithm, version, 'best_params.json')\n",
    "                if os.path.exists(best_params_path):\n",
    "                    print(f\"[Skip] Already found best_params.json for version: {version}\")\n",
    "                    continue\n",
    "        \n",
    "                for i in range(1, n_trials + 1):\n",
    "                    path = os.path.join('experiments', prefixes[idx], algorithm, version, f'trial_{i}')\n",
    "                    shutil.rmtree(path, ignore_errors=True)\n",
    "                    os.makedirs(path)\n",
    "\n",
    "                def save_trial_parameters(study, trial):\n",
    "                    params_path = os.path.join('experiments', prefixes[idx], algorithm, version, f'trial_{trial.number+1}')\n",
    "                    os.makedirs(params_path, exist_ok=True)\n",
    "                    with open(os.path.join(params_path, 'params.json'), 'w') as f:\n",
    "                        json.dump(trial.params, f)\n",
    "                \n",
    "                study = optuna.create_study(direction='maximize', sampler=sampler, pruner=pruner)\n",
    "\n",
    "                study.optimize(\n",
    "                    lambda trial: objective(trial, train_data, val_data, val_transition, \n",
    "                                            target, version, algorithm, vae, perturbation), n_trials=n_trials, n_jobs=1, catch=(optuna.TrialPruned,), gc_after_trial=True, \n",
    "                    callbacks=[save_trial_parameters]\n",
    "                )\n",
    "                \n",
    "                from optuna.trial import TrialState\n",
    "                completed_trials = [t for t in study.trials if t.state == TrialState.COMPLETE]\n",
    "\n",
    "                if len(completed_trials) > 0:\n",
    "                    with open(os.path.join('experiments', prefixes[idx], algorithm, version, 'best_params.json'), 'w') as f:\n",
    "                        json.dump(study.best_params, f)\n",
    "                else:\n",
    "                    print(f\"[Skip] No completed trials for version: {version}, skipping best_params.json save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
