{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from rl import make_df, make_transition_test, Model\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('processed//train_id.csv',index_col=0)\n",
    "valid_id = pd.read_csv('processed/val_id.csv',index_col=0)\n",
    "test_id = pd.read_csv('processed/test_id.csv',index_col=0)\n",
    "temporal_id = pd.read_csv('processed/temporal_id.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_thres(true_label, prob):\n",
    "\n",
    "    unique_labels = np.unique(true_label)\n",
    "    pos_label = max(unique_labels) \n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_label, prob, pos_label=pos_label)\n",
    "\n",
    "    J = tpr - fpr\n",
    "    ix = np.argmax(J)\n",
    "    best_thresh = thresholds[ix]\n",
    "\n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(target, algorithm, version, test_transition):\n",
    "    path = f\"experiments/{target.lower()}/{algorithm}/{version}\"\n",
    "    trials = [f for f in os.listdir(path) if 'trial' in f.lower()]\n",
    "\n",
    "    def natural_sort_key(s):\n",
    "        return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "    trials = sorted([f for f in os.listdir(path) if 'trial' in f.lower()], key=natural_sort_key)\n",
    "\n",
    "    best_trial, best_epoch, best_value = None, None, float('-inf')\n",
    "    \n",
    "    for trial in trials:\n",
    "\n",
    "        valid_auroc_p_gat = torch.load(f\"{path}/{trial}/valid_auroc_p_gat.pth\")\n",
    "        valid_auroc_p_med = torch.load(f\"{path}/{trial}/valid_auroc_p_med.pth\")\n",
    "\n",
    "        auroc_values = [x + y for x, y in zip(valid_auroc_p_gat, valid_auroc_p_med)]\n",
    "        max_value, max_epoch = max((v, i+1) for i, v in enumerate(auroc_values))\n",
    "        \n",
    "        if max_value > best_value:\n",
    "            best_value = max_value\n",
    "            best_epoch = max_epoch\n",
    "            best_trial = trial\n",
    "\n",
    "    params = json.load(open(f\"{path}/{best_trial}/params.json\"))\n",
    "    \n",
    "    valid_keys = {'mlp_size', 'mlp_num_layers', 'activation_type'} \n",
    "    filtered_params = {k: v for k, v in params.items() if k in valid_keys}\n",
    "    \n",
    "    obs_dim, nb_actions = test_transition.dataset.tensors[0].shape[1], max(test_transition.dataset.tensors[1])\n",
    "    network = Model(obs_dim=obs_dim, nb_actions=nb_actions, **filtered_params).to(device)\n",
    "    target_network = Model(obs_dim=obs_dim, nb_actions=nb_actions, **filtered_params).to(device)\n",
    "\n",
    "    for model, name in zip([network, target_network], [\"network\", \"target_network\"]):\n",
    "        model_path = f\"{path}/{best_trial}/{name}_{best_epoch}.pth\"\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    q_values, rewards, patients, actions = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for s, a, r, rp in test_transition:\n",
    "            s, a = s.to(device), a.to(device).long() - 1\n",
    "            q = network(s)\n",
    "\n",
    "            if version == '_negative':\n",
    "                r_clamped = torch.clamp(r, min=-1.0, max=0.0)\n",
    "                rp_clamped = torch.clamp(rp, min=-1.0, max=0.0)\n",
    "                q_clamped = torch.clamp(q, min=-1.0, max=0.0)\n",
    "            elif version == '_positive':\n",
    "                r_clamped = torch.clamp(r, min=0.0, max=1.0)\n",
    "                rp_clamped = torch.clamp(rp, min=0.0, max=1.0)\n",
    "                q_clamped = torch.clamp(q, min=0.0, max=1.0)\n",
    "            else:\n",
    "                r_clamped = torch.clamp(r, min=-1.0, max=1.0)\n",
    "                rp_clamped = torch.clamp(rp, min=-1.0, max=1.0)\n",
    "                q_clamped = torch.clamp(q, min=-1.0, max=1.0)\n",
    "\n",
    "\n",
    "            q_values.append(q_clamped.cpu().numpy())\n",
    "            rewards.append(r_clamped.cpu().numpy())\n",
    "            patients.append(rp_clamped.cpu().numpy())\n",
    "            actions.append(a.cpu().numpy())\n",
    "\n",
    "    q_values, rewards, patients, actions = map(np.concatenate, [q_values, rewards, patients, actions])\n",
    "    q_metrics = {stat: func(q_values, axis=1) for stat, func in zip([\"max\", \"min\", \"med\"], [np.max, np.min, np.median])}\n",
    "    q_metrics[\"gat\"] = q_values[np.arange(q_values.shape[0]), actions]\n",
    "\n",
    "    aurocs = {f\"auroc_p_{k}\": round(roc_auc_score(patients, v), 3) for k, v in q_metrics.items()}\n",
    "    if version != '_both':\n",
    "        aurocs.update({f\"auroc_{k}\": round(roc_auc_score(rewards, v), 3) for k, v in q_metrics.items()})\n",
    "    \n",
    "    thresholds = {f\"threshold_p_{k}\": cal_thres(patients, v) for k, v in q_metrics.items()}\n",
    "    if version != '_both':\n",
    "        thresholds.update({f\"threshold_{k}\": cal_thres(rewards, v) for k, v in q_metrics.items()})\n",
    "\n",
    "    def bootstrap_ci(y_true, y_pred, n_bootstraps=1000, ci=95):\n",
    "        bootstrapped_scores = []\n",
    "        rng = np.random.RandomState(42)\n",
    "\n",
    "        for _ in range(n_bootstraps):\n",
    "            while True:\n",
    "                indices = rng.randint(0, len(y_true), len(y_true))\n",
    "                if len(np.unique(y_true[indices])) >= 2:\n",
    "                    break\n",
    "            score = roc_auc_score(y_true[indices], y_pred[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "        \n",
    "        sorted_scores = np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "        lower = round(np.percentile(sorted_scores, (100 - ci) / 2), 3)\n",
    "        upper = round(np.percentile(sorted_scores, 100 - (100 - ci) / 2), 3)\n",
    "        return lower, upper\n",
    "\n",
    "    auroc_ci = {}\n",
    "    for k, v in q_metrics.items():\n",
    "        auroc_ci[f\"auroc_p_{k}_ci\"] = bootstrap_ci(patients, v)\n",
    "        if version != '_both':\n",
    "            auroc_ci[f\"auroc_{k}_ci\"] = bootstrap_ci(rewards, v)\n",
    "\n",
    "    return (network, target_network, q_values, rewards, patients, actions, *q_metrics.values(), *aurocs.values(), thresholds, auroc_ci, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_baseline(train_path, test_df):\n",
    "    train_RAW = pd.read_csv(train_path)\n",
    "    test_df_baseline = test_df.copy(deep=True)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    col_groups = {\n",
    "        'norm': ['age', 'Weight', 'GCS', 'Heartrate', 'Systolic_BP', 'Diastolic_BP', 'Mean_BP', 'Resprate', 'Temperature', 'FiO2',\n",
    "                 'Potassium', 'Sodium', 'Chloride', 'Glucose', 'Magnesium', 'Calcium', 'Hemoglobin', 'WBC', 'Platelets', 'PTT', 'PT',\n",
    "                 'Arterial_ph', 'PaO2', 'PaCO2', 'BaseExcess', 'Bicarbonate', 'Lactate', 'SOFA', 'SIRS', 'Shock_Index', 'PaO2/FiO2',\n",
    "                 'Cumulated_balance', 'elixhauser'],\n",
    "        'log': ['SpO2', 'BUN', 'SCr', 'SGOT', 'SGPT', 'Total_Bilirubin', 'INR', 'output_total', 'output_4hr'],\n",
    "        'bin': ['gender', 're_admission', 'MV'] + ['action_{}_prev'.format(i) for i in range(1, 10)]\n",
    "    }\n",
    "\n",
    "    for group, cols in col_groups.items():\n",
    "        for col in cols:\n",
    "            prefixed_col = f's:{col}'\n",
    "            if group == 'norm':\n",
    "                scaler.fit(train_RAW[[col]])\n",
    "                mean, std = scaler.mean_[0], scaler.scale_[0]\n",
    "                test_df_baseline[prefixed_col] = -(mean/std)\n",
    "            elif group == 'log':\n",
    "                scaler.fit(train_RAW[[col]])\n",
    "                mean, std = scaler.mean_[0], scaler.scale_[0]\n",
    "                test_df_baseline[prefixed_col] = (np.log(0.1) - mean) / std\n",
    "            elif group == 'bin':\n",
    "                test_df_baseline[prefixed_col] = -0.5\n",
    "\n",
    "    return test_df_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "for target in tqdm(['Dead_icu', 'Dead_hosp', 'Dead_90', 'AKI_rrt', 'AKI_48', 'AKI_24', 'AKI_12', 'Septic_shock']):\n",
    "\n",
    "    data_dict[target] = {} \n",
    "\n",
    "    data = pd.read_csv(f'processed/df_{target}.csv')\n",
    "\n",
    "    if 'Septic' in target : reward = 'r:reward_septic_shock'\n",
    "    elif 'Dead' in target : reward = 'r:reward_dead'\n",
    "    else : reward = 'r:reward_aki'\n",
    "\n",
    "    data[reward] = data.groupby('traj')[reward].transform(lambda x: x[:-1].tolist() + ([1] if x.iloc[-1] == 0 else [x.iloc[-1]]))\n",
    "\n",
    "    train_df, valid_df, test_df = make_df(data, reward, train_id, valid_id, test_id)\n",
    "    train_df, valid_df, temporal_df = make_df(data, reward, train_id, valid_id, temporal_id)\n",
    "    test_transition = make_transition_test(test_df, reward, rolling_size=1)\n",
    "    temporal_transition = make_transition_test(temporal_df, reward, rolling_size=1)\n",
    "\n",
    "    test_df_baseline = process_baseline('processed/train_df_RAW.csv', test_df)\n",
    "    test_df_baseline_transition = make_transition_test(test_df_baseline, reward, rolling_size=1)\n",
    "\n",
    "    data_dict[target] = {\n",
    "        \"train\": train_df,\n",
    "        \"valid\": valid_df,\n",
    "        \"test\": test_df,\n",
    "        \"temporal\": temporal_df,\n",
    "        \"test_transition\": test_transition,\n",
    "        \"temporal_transition\": temporal_transition,\n",
    "        \"test_df_baseline_transition\": test_df_baseline_transition\n",
    "    }\n",
    "\n",
    "    for algorithm in ['_ddqn','_cql','_iql','_bcq']:\n",
    "\n",
    "        data_dict[target][algorithm] = {}\n",
    "    \n",
    "        for version in ['_negative', '_positive', '_both']:\n",
    "\n",
    "            data_dict[target][algorithm][version] = {}\n",
    "            \n",
    "            def process_transitions(target, algorithm, version, transitions, data_dict):\n",
    "\n",
    "                for transition_type, transition in transitions.items():\n",
    "\n",
    "                    results = test(target, algorithm, version, transition)\n",
    "\n",
    "                    if version == \"_both\":\n",
    "                        (network, target_network, q_value, r_arr, patient, action_space, q_max, q_min, q_median, q_gather,\n",
    "                        test_auroc_p_gat, test_auroc_p_med, test_auroc_p_min, test_auroc_p_max,\n",
    "                        thresholds, auroc_ci, params) = results\n",
    "\n",
    "                        test_auroc_gat = test_auroc_med = test_auroc_min = test_auroc_max = None\n",
    "                    else:\n",
    "                        (network, target_network, q_value, r_arr, patient, action_space, q_max, q_min, q_median, q_gather,\n",
    "                        test_auroc_p_gat, test_auroc_p_med, test_auroc_p_min, test_auroc_p_max,\n",
    "                        test_auroc_gat, test_auroc_med, test_auroc_min, test_auroc_max,\n",
    "                        thresholds, auroc_ci, params) = results\n",
    "\n",
    "                    data_dict[target][algorithm][version][transition_type] = {\n",
    "                        \"q_value\": q_value,\n",
    "                        \"reward\": r_arr,\n",
    "                        \"patient\": patient,\n",
    "                        \"action_space\": action_space,\n",
    "                        \"q_max\": q_max,\n",
    "                        \"q_min\": q_min,\n",
    "                        \"q_median\": q_median,\n",
    "                        \"q_gather\": q_gather,\n",
    "                        \"auroc_p_gat\": test_auroc_p_gat,\n",
    "                        \"auroc_p_med\": test_auroc_p_med,\n",
    "                        \"auroc_p_min\": test_auroc_p_min,\n",
    "                        \"auroc_p_max\": test_auroc_p_max,\n",
    "                        \"thresholds\": thresholds,\n",
    "                        \"auroc_ci\": auroc_ci,\n",
    "                        'network': network,\n",
    "                        'target_network': target_network,\n",
    "                        'params': params\n",
    "                    }\n",
    "\n",
    "                    if version != \"_both\":\n",
    "                        data_dict[target][algorithm][version][transition_type].update({\n",
    "                            \"auroc_gat\": test_auroc_gat,\n",
    "                            \"auroc_med\": test_auroc_med,\n",
    "                            \"auroc_min\": test_auroc_min,\n",
    "                            \"auroc_max\": test_auroc_max\n",
    "                        })\n",
    "\n",
    "                    print(f\"Target: {target}, algorithm: {algorithm}, version: {version}, transition: {transition_type}\")\n",
    "\n",
    "                    auroc_keys = [\"auroc_p_gat\", \"auroc_p_med\", \"auroc_p_min\", \"auroc_p_max\"]\n",
    "                    auroc_ci_keys = [f\"auroc_p_{k}_ci\" for k in [\"gat\", \"med\", \"min\", \"max\"]]\n",
    "\n",
    "                    if version != '_both':\n",
    "                        auroc_keys += [\"auroc_gat\", \"auroc_med\", \"auroc_min\", \"auroc_max\"]\n",
    "                        auroc_ci_keys += [f\"auroc_{k}_ci\" for k in [\"gat\", \"med\", \"min\", \"max\"]]\n",
    "\n",
    "                    for key in auroc_keys:\n",
    "                        print(f\"{key}: {data_dict[target][algorithm][version][transition_type][key]}\")\n",
    "\n",
    "                    for key in auroc_ci_keys:\n",
    "                        ci_value = data_dict[target][algorithm][version][transition_type][\"auroc_ci\"].get(key, 'N/A')\n",
    "                        print(f\"{key}: {ci_value}\")\n",
    "\n",
    "                    print(\"-\" * 50)\n",
    "\n",
    "                return data_dict\n",
    "\n",
    "            transitions = {\n",
    "                'test': data_dict[target]['test_transition'],\n",
    "                'temporal': data_dict[target]['temporal_transition']\n",
    "            }\n",
    "\n",
    "            data_dict = process_transitions(target, algorithm, version, transitions, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_dict, 'processed/data_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = torch.load('processed/data_dict.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_BAR_COLOR = 'blue'\n",
    "POS_MEAN_COLOR = 'navy'\n",
    "POS_STD_COLOR = 'dodgerblue'\n",
    "\n",
    "NEG_BAR_COLOR = 'red'\n",
    "NEG_MEAN_COLOR = 'darkred'\n",
    "NEG_STD_COLOR = 'salmon'\n",
    "\n",
    "for target in tqdm(['Dead_icu', 'AKI_rrt', 'Septic_shock']):\n",
    "    data = pd.read_csv(f'processed/df_{target}.csv', index_col=0)\n",
    "\n",
    "    if 'Septic' in target:\n",
    "        reward = 'r:reward_septic_shock'\n",
    "    elif 'Dead' in target:\n",
    "        reward = 'r:reward_dead'\n",
    "    else:\n",
    "        reward = 'r:reward_aki'\n",
    "\n",
    "    left_label, right_label = 'Positive', 'Negative'\n",
    "\n",
    "    for algorithm in ['_iql']:\n",
    "        for version in ['_negative', '_positive', '_both']:\n",
    "            q_value = data_dict[target][algorithm][version]['test']['q_value']\n",
    "            unique_conditions = np.unique(data_dict[target]['test'][reward])\n",
    "            unique_conditions_range = np.unique(data_dict[target][algorithm][version]['test']['reward'])\n",
    "\n",
    "            positive_traj = (\n",
    "                data_dict[target]['test']\n",
    "                .groupby('traj')\n",
    "                .filter(lambda x: x.iloc[-1][reward] in [max(unique_conditions)])['traj']\n",
    "                .drop_duplicates()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            negative_traj = (\n",
    "                data_dict[target]['test']\n",
    "                .groupby('traj')\n",
    "                .filter(lambda x: x.iloc[-1][reward] in [min(unique_conditions)])['traj']\n",
    "                .drop_duplicates()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            data_ = (\n",
    "                data_dict[target]['test']\n",
    "                .groupby('traj', group_keys=False)\n",
    "                .apply(lambda x: x.iloc[:-1])\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "            action = [\n",
    "                'No-Medication', 'Cephalosporin', 'Glycopeptide',\n",
    "                'Beta-lactam', 'Carbapenem', 'Penicillin',\n",
    "                'Minor Antibiotic', 'Selective Antimicrobial', 'Combination'\n",
    "            ]\n",
    "\n",
    "            q_value_df = pd.DataFrame(q_value, columns=action)\n",
    "            combined_df = pd.concat([data_, q_value_df], axis=1)\n",
    "\n",
    "            negative_df = pd.merge(combined_df, negative_traj, on='traj', how='inner')\n",
    "            positive_df = pd.merge(combined_df, positive_traj, on='traj', how='inner')\n",
    "\n",
    "            fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "\n",
    "            if version == '_positive':\n",
    "                name = 'R-network'\n",
    "            if version == '_negative':\n",
    "                name = 'D-network'\n",
    "            if version == '_both':\n",
    "                name = 'C-network'\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"{name}\\nBlue: {left_label} | Red: {right_label}\",\n",
    "                fontsize=20, fontweight='bold'\n",
    "            )\n",
    "\n",
    "            for i, c in enumerate(action):\n",
    "                row_idx = i // 3\n",
    "                col_idx = i % 3\n",
    "                ax = axes[row_idx, col_idx]\n",
    "\n",
    "                neg_data_col = negative_df[c].dropna()\n",
    "                pos_data_col = positive_df[c].dropna()\n",
    "\n",
    "                if len(neg_data_col) > 0:\n",
    "                    counts_neg, bins_neg = np.histogram(neg_data_col, bins=50)\n",
    "                    bin_width = bins_neg[1] - bins_neg[0]\n",
    "                    midpoints_neg = 0.5 * (bins_neg[1:] + bins_neg[:-1])\n",
    "                    ratio_neg = counts_neg / counts_neg.sum()\n",
    "                    data_dict[target][algorithm][version]['test'][f'ratio_neg_{c}'] = ratio_neg\n",
    "                    ax.bar(midpoints_neg, ratio_neg, width=bin_width, color=NEG_BAR_COLOR, alpha=0.3, label=f\"{right_label}\")\n",
    "                    neg_mean = neg_data_col.mean()\n",
    "                    neg_std = neg_data_col.std()\n",
    "                    ax.fill_betweenx(y=[0, 1], x1=neg_mean - neg_std, x2=neg_mean + neg_std, color=NEG_STD_COLOR, alpha=0.3,\n",
    "                                     label=f\"{right_label} ±1σ\" if i == 0 else None)\n",
    "                    ax.axvline(neg_mean, color=NEG_MEAN_COLOR, linestyle='--', label=f\"{right_label} Mean\" if i == 0 else None)\n",
    "\n",
    "                if len(pos_data_col) > 0:\n",
    "                    counts_pos, bins_pos = np.histogram(pos_data_col, bins=50)\n",
    "                    bin_width_pos = bins_pos[1] - bins_pos[0]\n",
    "                    midpoints_pos = 0.5 * (bins_pos[1:] + bins_pos[:-1])\n",
    "                    ratio_pos = counts_pos / counts_pos.sum()\n",
    "                    data_dict[target][algorithm][version]['test'][f'ratio_pos_{c}'] = ratio_pos\n",
    "                    ax.bar(midpoints_pos, ratio_pos, width=bin_width_pos, color=POS_BAR_COLOR, alpha=0.3, label=f\"{left_label}\")\n",
    "                    pos_mean = pos_data_col.mean()\n",
    "                    pos_std = pos_data_col.std()\n",
    "                    ax.fill_betweenx(y=[0, 1], x1=pos_mean - pos_std, x2=pos_mean + pos_std, color=POS_STD_COLOR, alpha=0.3,\n",
    "                                     label=f\"{left_label} ±1σ\" if i == 0 else None)\n",
    "                    ax.axvline(pos_mean, color=POS_MEAN_COLOR, linestyle='--', label=f\"{left_label} Mean\" if i == 0 else None)\n",
    "\n",
    "                ax.set_title(c, fontsize=18)\n",
    "\n",
    "                if version != 'both':\n",
    "                    min_x = min(unique_conditions_range)\n",
    "                    max_x = max(unique_conditions_range)\n",
    "                else:\n",
    "                    min_x = -1.0\n",
    "                    max_x = +1.0\n",
    "\n",
    "                start_tick = math.floor(min_x * 5) / 5.0\n",
    "                end_tick = math.ceil(max_x * 5) / 5.0\n",
    "                x_ticks = np.arange(start_tick, end_tick + 0.001, 0.2)\n",
    "                ax.set_xticks(x_ticks)\n",
    "                ax.set_xticklabels([f\"{tick:.1f}\" for tick in x_ticks], fontsize=12)\n",
    "                ax.set_xlim(min_x, max_x)\n",
    "\n",
    "                ax.set_ylim(0, 0.31)\n",
    "                y_ticks = np.arange(0.05, 0.31, 0.05)\n",
    "                ax.set_yticks(y_ticks)\n",
    "                ax.set_yticklabels(y_ticks, fontsize=12)\n",
    "                ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda val, _: f\"{val*100:.1f}%\"))\n",
    "                ax.grid(False)\n",
    "\n",
    "            if version == '_positive':\n",
    "                fig.text(0.03, 0.5, \"Relative proportion\", va='center', rotation='vertical', fontsize=18)\n",
    "\n",
    "            handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "            legend_dict = dict(zip(labels, handles))\n",
    "\n",
    "            if target == 'Septic_shock':\n",
    "                fig.text(0.5, 0.04, \"Q-value\", ha='center', fontsize=18)\n",
    "                fig.legend(legend_dict.values(), legend_dict.keys(), loc='lower center', bbox_to_anchor=(0.5, 0.00),\n",
    "                           ncol=6, frameon=True, fontsize=15)\n",
    "\n",
    "            plt.tight_layout(rect=[0.05, 0.06, 0.95, 0.98])\n",
    "            plt.savefig(f'figure/{target}{algorithm}{version}.png', dpi=300)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_flag_plot(\n",
    "    positive_df, negative_df,\n",
    "    positive_df_RAW, negative_df_RAW,\n",
    "    left_label, right_label,\n",
    "    algorithm, threshold,\n",
    "    data_dict, target\n",
    "):\n",
    "    t = [-6, -5, -4, -3, -2, -1, 0, +1, +2, +3, +4]\n",
    "\n",
    "    predefined_vars = [\n",
    "        'q_positive_median',\n",
    "        'q_negative_median',\n",
    "        'q_positive_gather',\n",
    "        'q_negative_gather'\n",
    "    ]\n",
    "\n",
    "    s_col = [x for x in data_dict[target]['test'] if x.startswith('s:')]\n",
    "    exclude_vars = ['prev', 'age', 'Weight', 're_admission', 'elixhauser', 'gender', 'MV', 'Glucose', 'FiO2', 'SGPT', 'SGOT', 'output_total', 'output_4hr', 'Cumulated_balance',' Arterial_ph', 'WBC']\n",
    "    include_vars = ['Lactate', 'BUN', 'Diastolic_BP', 'Heartrate', 'INR', 'Resprate', 'SpO2', 'Systolic_BP', 'Temperature', 'GCS', 'SOFA', 'SIRS']\n",
    "    s_col = [x for x in s_col if not any(ex in x for ex in exclude_vars)]\n",
    "    s_col = [x for x in s_col if any(ex in x for ex in include_vars)]\n",
    "\n",
    "    treatments = ['input_4hr','max_vaso', 'AKI_max_stage']\n",
    "    all_vars = predefined_vars + treatments + s_col\n",
    "\n",
    "    def map_variable_name(var_name):\n",
    "        if var_name.startswith('s:'):\n",
    "            title = var_name[2:].replace('_', ' ')\n",
    "        else:\n",
    "            title = var_name.replace('_', ' ')\n",
    "        title = re.sub(r'\\bSpo2\\b', 'SpO$_2$', title, flags=re.IGNORECASE)\n",
    "        title = title[0].upper() + title[1:]\n",
    "        if 'median' in var_name and not 'vaso' in var_name:\n",
    "            base = 'V'\n",
    "        elif 'gather' in var_name:\n",
    "            base = 'Q'\n",
    "        else:\n",
    "            base = title\n",
    "        if 'positive' in var_name:\n",
    "            suffix = '_R'\n",
    "        elif 'negative' in var_name:\n",
    "            suffix = '_D'\n",
    "        else:\n",
    "            suffix = ''\n",
    "        if suffix:\n",
    "            new_label = f\"{base}$_{{{suffix[1]}}}$\"\n",
    "        else:\n",
    "            new_label = base\n",
    "        return new_label, var_name\n",
    "\n",
    "    mapped_vars = [map_variable_name(var) for var in all_vars]\n",
    "\n",
    "    special_original_vars = [\n",
    "        'q_positive_median',\n",
    "        'q_negative_median',\n",
    "        'q_positive_gather',\n",
    "        'q_negative_gather'\n",
    "    ]\n",
    "\n",
    "    special_mapped_vars = [mv for mv in mapped_vars if mv[1] in special_original_vars]\n",
    "    main_mapped_vars = [mv for mv in mapped_vars if mv[1] not in special_original_vars]\n",
    "\n",
    "    num_main = len(main_mapped_vars)\n",
    "    num_special = len(special_mapped_vars)\n",
    "\n",
    "    plots_per_row = 5\n",
    "    rows_main = math.ceil(num_main / plots_per_row) if num_main > 0 else 0\n",
    "    total_rows = rows_main + (1 if num_special > 0 else 0)\n",
    "    total_subplots = num_main + num_special + 1\n",
    "\n",
    "    fig_width = 4 * plots_per_row * 0.5\n",
    "    fig_height = 3 * total_rows * 0.5\n",
    "    fig, axes = plt.subplots(total_rows, plots_per_row, figsize=(fig_width, fig_height), sharex=True, sharey=False)\n",
    "\n",
    "    if total_rows == 1:\n",
    "        axes = np.array(axes).reshape(-1)\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    legend_ax = None\n",
    "    if total_subplots > plots_per_row * total_rows:\n",
    "        legend_ax = axes[-1]\n",
    "    else:\n",
    "        legend_ax = axes[plots_per_row * total_rows - 1]\n",
    "\n",
    "    ax_idx = 0\n",
    "\n",
    "    name = [left_label, right_label]\n",
    "    df = [positive_df, negative_df]\n",
    "    df_RAW = [positive_df_RAW, negative_df_RAW]\n",
    "    colors = ['blue', 'orange']\n",
    "\n",
    "    ytick_values = {\n",
    "        'BaseExcess': [-5, 0, 5], 'Lactate': [0, 5], 'Arterial_ph': [7.3, 7.4],\n",
    "        'BUN': [25, 50, 75], 'Calcium': [8, 9], 'Chloride': [100, 110], 'SCr': [0, 2.5],\n",
    "        'Diastolic BP': [50, 75], 'FiO2': [0.5, 0.75], 'GCS': [5, 10, 15], 'Glucose': [100, 200],\n",
    "        'Bicarbonate': [20, 30], 'Heartrate': [75, 100], 'Hemoglobin': [10.0, 12.5], 'INR': [1, 3],\n",
    "        'Magnesium': [2, 2.5], 'Mean_BP': [60, 80], 'PT': [10, 30], 'PTT': [25, 75],\n",
    "        'PaO2/FiO2': [0, 500], 'Platelets': [100, 200, 300], 'Potassium': [3.5, 4.0, 4.5],\n",
    "        'Resprate': [20, 30], 'SGOT': [0, 1000], 'SGPT': [0, 1000], 'SIRS': [0, 3],\n",
    "        'SOFA': [5, 10, 15], 'Shock_Index': [0.75, 1.00, 1.25], 'Sodium': [135, 140, 145],\n",
    "        'SpO$_2$': [90, 100], 'Systolic BP': [100, 125], 'Temperature': [36, 38], 'Total_Bilirubin': [0, 10],\n",
    "        'WBC': [0, 20], 'Cumulated_balance': [0, 25000], 'MV': [0, 1],\n",
    "        'output_4hr': [0, 500], 'output_total': [0, 25000], 'PaCO2': [30, 40, 50], 'PaO2': [100, 200],\n",
    "        'Input 4hr': [0, 1000], 'input_total': [0, 30000], 'median_vaso': [0, 2], 'Max vaso': [0, 5], 'AKI max stage': [0, 3],\n",
    "        'V$_{D}$': [-0.25, 0.00], 'V$_{R}$': [0.75, 1.00], 'Q$_{D}$': [-0.25, 0.00], 'Q$_{R}$': [0.75, 1.00]\n",
    "    }\n",
    "\n",
    "    def get_yticks(variable):\n",
    "        return ytick_values.get(variable, [])\n",
    "\n",
    "    def plot_variable(ax, var_title, var_name):\n",
    "        for j, label in enumerate(['positive', 'negative']):\n",
    "            df[j][treatments] = df_RAW[j][treatments]\n",
    "            condition = (df[j]['survivor'] == -j) & df[j]['first_flag'].isin(t)\n",
    "            grouped = df[j][condition].groupby('first_flag')[var_name]\n",
    "            mean = grouped.mean().reindex(t).values\n",
    "            std = grouped.std().reindex(t).values\n",
    "            ax.plot(t, mean, label=name[j], color=colors[j], linewidth=2)\n",
    "            ax.fill_between(t, mean - std, mean + std, alpha=0.3, color=colors[j])\n",
    "            ax.set_xlim(min(t), max(t))\n",
    "            ax.set_xticks(t)\n",
    "            ax.set_xticklabels([f'{4 * x}h' if ((x != 2) and (x != 4) and (x != -2) and (x != 0) and (x != -4) and (x != -5) and (x != 5)) else '' for x in t], fontsize=8)\n",
    "        ax.axvline(0, color='gray', linestyle='--')\n",
    "        ax.set_title(var_title, fontsize=8)\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_yticks(get_yticks(var_title))\n",
    "        ax.set_yticklabels(ax.get_yticks(), fontsize=8)\n",
    "\n",
    "    for var_title, var_name in main_mapped_vars:\n",
    "        if ax_idx >= len(axes) - 1:\n",
    "            break\n",
    "        ax = axes[ax_idx]\n",
    "        plot_variable(ax, var_title, var_name)\n",
    "        ax_idx += 1\n",
    "\n",
    "    for var_title, var_name in special_mapped_vars:\n",
    "        if ax_idx >= len(axes) - 1:\n",
    "            break\n",
    "        ax = axes[ax_idx]\n",
    "        plot_variable(ax, var_title, var_name)\n",
    "        ax_idx += 1\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    legend_ax.axis('off')\n",
    "    legend_ax.legend(handles, labels, loc='center', fontsize=12, frameon=False)\n",
    "\n",
    "    for idx in range(ax_idx, len(axes) - 1):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    if target == 'Septic_shock':\n",
    "        fig.text(0.5, 0.04, 'Time from First Flag', ha='center', fontsize=10)\n",
    "\n",
    "    plt.savefig(f'figure/{right_label}{algorithm}.png', dpi=300)\n",
    "    plt.tight_layout(rect=[0.02, 0.02, 0.98, 0.98])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_plot(flag_dict, q_values, left_label, right_label, algorithm, threshold):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(21, 9), dpi=300, constrained_layout=True)\n",
    "    step = flag_dict['step']\n",
    "    xaxis = np.arange(len(step), dtype=float)\n",
    "\n",
    "    q_min, q_max = -1, +1\n",
    "    from matplotlib.colors import TwoSlopeNorm\n",
    "    norm = TwoSlopeNorm(vcenter=0.0, vmin=q_min, vmax=q_max)\n",
    "    cmap = plt.cm.RdBu\n",
    "\n",
    "    if 'Last\\nSepsis' in step:\n",
    "        idx_last_sepsis = step.index('Last\\nSepsis')\n",
    "        if idx_last_sepsis + 1 < len(step):\n",
    "            xaxis[idx_last_sepsis+1:] += 0.5\n",
    "\n",
    "    conditions = ['V_flag_Clinician_flag', 'V_flag_Clinician_no', 'V_no_Clinician_flag', 'V_no_Clinician_no']\n",
    "    colors = []\n",
    "    alphas = [0.8, 0.6, 0.4, 0.2]\n",
    "\n",
    "    names = [left_label, right_label]\n",
    "\n",
    "    subplot_traj_types = ['positive', 'negative']\n",
    "    subplot_mean_q = []\n",
    "    for traj_type in subplot_traj_types:\n",
    "        cond_mean_q = []\n",
    "        for cond in conditions:\n",
    "            arr = [q for q in q_values[traj_type][cond] if not np.isnan(q)]\n",
    "            if len(arr) > 0:\n",
    "                avg_q = np.mean(arr)\n",
    "            else:\n",
    "                avg_q = 0.0\n",
    "            cond_mean_q.append(avg_q)\n",
    "        subplot_mean_q.append(cond_mean_q)\n",
    "\n",
    "    colors = ['red','yellow','darkgray','lightgray']\n",
    "\n",
    "    for i, traj_type in enumerate(['positive', 'negative']):\n",
    "        bottom = np.zeros(len(step))\n",
    "        vflag_vals = None\n",
    "        for cond, color, alpha in zip(conditions, colors, alphas):\n",
    "            vals = flag_dict[traj_type][cond]\n",
    "            q = q_values[traj_type][cond]\n",
    "\n",
    "            bars = ax[i].bar(xaxis, vals, bottom=bottom, color=color, alpha=alpha, label=cond, antialiased=True, rasterized=True)\n",
    "            bottom += vals\n",
    "\n",
    "            q_means = q\n",
    "            labels = [f'{v:.1%}\\n({qv:.2f})' if not (np.isnan(qv) or v < 0.05) else '' for v, qv in zip(vals, q_means)]\n",
    "            ax[i].bar_label(bars, labels=labels, label_type='center', fontsize=10)\n",
    "\n",
    "            if cond == 'V_no_Clinician_no':\n",
    "                vflag_vals = [1 - v for v in vals]\n",
    "\n",
    "        if vflag_vals is not None and len(step) > 2:\n",
    "            ax[i].plot(xaxis[2:], vflag_vals[2:], color='black', marker='o', linestyle='-', markersize=5)\n",
    "\n",
    "        ax[i].set_xticks(xaxis)\n",
    "        ax[i].set_xticklabels('', fontsize=15)\n",
    "\n",
    "        if target == 'Septic_shock':\n",
    "            ax[i].set_xticklabels(step, fontsize=15)\n",
    "\n",
    "        ax[i].set_title(names[i], fontsize=20)\n",
    "\n",
    "        if target == 'Septic_shock':\n",
    "            ax[i].set_xlabel(\"Time from Terminal state\", fontsize=15)\n",
    "\n",
    "        ax[i].set_yticks([0.2,0.4,0.6,0.8,1.0])\n",
    "        ax[i].set_yticklabels(['20%', '40%', '60%', '80%', '100%'], fontsize=15)\n",
    "        ax[i].set_ylim(0,1)\n",
    "\n",
    "    legend_patches_0 = []\n",
    "    for cond, color, a in zip(conditions, colors, alphas):\n",
    "        patch = plt.Rectangle((0,0),1,1, facecolor=color, alpha=a)\n",
    "        legend_patches_0.append((patch, cond))\n",
    "\n",
    "    if target == 'Septic_shock':\n",
    "        ax[0].legend(\n",
    "            [lp[0] for lp in legend_patches_0],\n",
    "            [lp[1] for lp in legend_patches_0],\n",
    "            loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=4, fontsize=10\n",
    "        )\n",
    "\n",
    "    legend_patches_1 = []\n",
    "    for cond, color, a in zip(conditions, colors, alphas):\n",
    "        patch = plt.Rectangle((0,0),1,1, facecolor=color, alpha=a)\n",
    "        legend_patches_1.append((patch, cond))\n",
    "    \n",
    "    if target == 'Septic_shock':\n",
    "        ax[1].legend(\n",
    "            [lp[0] for lp in legend_patches_1],\n",
    "            [lp[1] for lp in legend_patches_1],\n",
    "            loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=4, fontsize=10\n",
    "        )\n",
    "\n",
    "    if 'Last\\nSepsis' in step:\n",
    "        idx_last_sepsis = step.index('Last\\nSepsis')\n",
    "        if idx_last_sepsis + 1 < len(step):\n",
    "            mid_point = (xaxis[idx_last_sepsis] + xaxis[idx_last_sepsis+1])/2\n",
    "            ax[0].axvline(x=mid_point, color='black', linewidth=0.75)\n",
    "            ax[1].axvline(x=mid_point, color='black', linewidth=0.75)\n",
    "\n",
    "    plt.savefig(f'figure/Flag_analysis_{right_label}{algorithm}_{threshold}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def compute_flag_data(positive_df, negative_df, selected_steps):\n",
    "    flag_dict = {'step': selected_steps, 'positive': {}, 'negative': {}}\n",
    "    q_values = {'positive': {}, 'negative': {}}\n",
    "\n",
    "    conditions = ['V_no_Clinician_no', 'V_no_Clinician_flag', 'V_flag_Clinician_no', 'V_flag_Clinician_flag']\n",
    "    \n",
    "    for traj_type in ['positive', 'negative']:\n",
    "        flag_dict[traj_type] = {c: [] for c in conditions}\n",
    "        q_values[traj_type] = {c: [] for c in conditions}\n",
    "\n",
    "    df_list = [positive_df, negative_df]\n",
    "    traj_types = ['positive', 'negative']\n",
    "\n",
    "    last_sepsis_pos = positive_df[positive_df['sepsis'] == 1].groupby('traj').apply(lambda x: x.iloc[-1])\n",
    "    last_sepsis_neg = negative_df[negative_df['sepsis'] == 1].groupby('traj').apply(lambda x: x.iloc[-1])\n",
    "\n",
    "    for traj_type_i, traj_type in enumerate(traj_types):\n",
    "        df_traj = df_list[traj_type_i]\n",
    "\n",
    "        if traj_type == 'positive':\n",
    "            q_col = 'q_positive_median'\n",
    "            last_sepsis_data = last_sepsis_pos\n",
    "        else:\n",
    "            q_col = 'q_negative_median'\n",
    "            last_sepsis_data = last_sepsis_neg\n",
    "\n",
    "        for t in selected_steps:\n",
    "            if t == 'Sepsis':\n",
    "                tmp = df_traj[df_traj['sepsis'] == 1]\n",
    "            elif t == 'Last\\nSepsis':\n",
    "                tmp = last_sepsis_data\n",
    "            else:\n",
    "                tmp = df_traj[df_traj['Time'] == t]\n",
    "\n",
    "            total = len(tmp)\n",
    "\n",
    "            subsets = {\n",
    "                'V_no_Clinician_no': tmp[tmp['V_no_Clinician_no'] == 1],\n",
    "                'V_no_Clinician_flag': tmp[tmp['V_no_Clinician_flag'] == 1],\n",
    "                'V_flag_Clinician_no': tmp[tmp['V_flag_Clinician_no'] == 1],\n",
    "                'V_flag_Clinician_flag': tmp[tmp['V_flag_Clinician_flag'] == 1]\n",
    "            }\n",
    "\n",
    "            for cond in conditions:\n",
    "                count = len(subsets[cond])\n",
    "                ratio = count / total if total > 0 else 0\n",
    "                mean_q = subsets[cond][q_col].mean() if count > 0 else np.nan\n",
    "\n",
    "                flag_dict[traj_type][cond].append(ratio)\n",
    "                q_values[traj_type][cond].append(mean_q)\n",
    "\n",
    "    return flag_dict, q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in tqdm(['Dead_icu', 'AKI_rrt', 'Septic_shock']):\n",
    "\n",
    "    data = pd.read_csv(f'processed/df_{target}.csv', index_col=0)\n",
    "\n",
    "    if 'Septic' in target : reward = 'r:reward_septic_shock'\n",
    "    elif 'Dead' in target : reward = 'r:reward_dead'\n",
    "    else : reward = 'r:reward_aki'\n",
    "\n",
    "    if 'Dead' in target:\n",
    "        left_label, right_label = 'Discharge', target\n",
    "    elif 'rrt' in target:\n",
    "        left_label, right_label = 'No-RRT', 'RRT'\n",
    "    elif 'AKI' in target:\n",
    "        left_label, right_label = 'No-C'+target, 'C'+target\n",
    "    elif 'Septic' in target:\n",
    "        left_label, right_label = 'No-Shock', 'Shock'\n",
    "    else:\n",
    "        left_label, right_label = 'Positive', 'Negative'\n",
    "\n",
    "    for algorithm in ['_iql']:\n",
    "\n",
    "        for threshold in ['threshold_p']:\n",
    "\n",
    "            for source in ['test']:\n",
    "\n",
    "                data = data_dict[target][source] \n",
    "                unique_conditions = np.unique(data[reward])\n",
    "                positive_traj = data.groupby('traj').filter(lambda x: x.iloc[-1][reward] in [max(unique_conditions)])['traj'].drop_duplicates().reset_index(drop=True)\n",
    "                negative_traj = data.groupby('traj').filter(lambda x: x.iloc[-1][reward] in [min(unique_conditions)])['traj'].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "                data['max_step'] = data.groupby('traj')['step'].transform('max')\n",
    "                data['step_before'] = data['max_step'] - data['step']\n",
    "\n",
    "                def survivor(data):\n",
    "                    if data[reward].sum() == 1: \n",
    "                        data['survivor'] = 0\n",
    "                        return data['survivor'] \n",
    "                    \n",
    "                    else:\n",
    "                        data['survivor'] = -1\n",
    "                        return data['survivor']\n",
    "                    \n",
    "                data['survivor'] = data.groupby('traj').apply(survivor).reset_index(drop=True) \n",
    "                data = data.groupby('traj', group_keys=False).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "                \n",
    "                data['q_negative_median'] = data_dict[target][algorithm]['_negative'][source]['q_median']\n",
    "                data['q_positive_median'] = data_dict[target][algorithm]['_positive'][source]['q_median']\n",
    "\n",
    "                data['q_negative_gather'] = data_dict[target][algorithm]['_negative'][source]['q_gather']\n",
    "                data['q_positive_gather'] = data_dict[target][algorithm]['_positive'][source]['q_gather']\n",
    "\n",
    "                data['median_flag'] = ((data_dict[target][algorithm]['_positive'][source]['q_median'] <= data_dict[target][algorithm]['_positive'][source]['thresholds'][threshold+'_med']) & \n",
    "                                    (data_dict[target][algorithm]['_negative'][source]['q_median'] <= data_dict[target][algorithm]['_negative'][source]['thresholds'][threshold+'_med'])).astype(int)\n",
    "\n",
    "                data['min_flag'] = ((data_dict[target][algorithm]['_positive'][source]['q_min'] <= data_dict[target][algorithm]['_positive'][source]['thresholds'][threshold+'_min']) & \n",
    "                                    (data_dict[target][algorithm]['_negative'][source]['q_min'] <= data_dict[target][algorithm]['_negative'][source]['thresholds'][threshold+'_min'])).astype(int)\n",
    "\n",
    "                data['max_flag'] = ((data_dict[target][algorithm]['_positive'][source]['q_max'] <= data_dict[target][algorithm]['_positive'][source]['thresholds'][threshold+'_max']) & \n",
    "                                    (data_dict[target][algorithm]['_negative'][source]['q_max'] <= data_dict[target][algorithm]['_negative'][source]['thresholds'][threshold+'_max'])).astype(int)\n",
    "\n",
    "                data['gather_flag'] = ((data_dict[target][algorithm]['_positive'][source]['q_gather'] <= data_dict[target][algorithm]['_positive'][source]['thresholds'][threshold+'_gat']) & \n",
    "                                    (data_dict[target][algorithm]['_negative'][source]['q_gather'] <= data_dict[target][algorithm]['_negative'][source]['thresholds'][threshold+'_gat'])).astype(int)\n",
    "\n",
    "                data['V_no_Clinician_no'] = ((data['median_flag'] == 0) & (data['gather_flag'] == 0)).astype(int)\n",
    "                data['V_no_Clinician_flag'] = ((data['median_flag'] == 0) & (data['gather_flag'] == 1)).astype(int)\n",
    "                data['V_flag_Clinician_no'] = ((data['median_flag'] == 1) & (data['gather_flag'] == 0)).astype(int)\n",
    "                data['V_flag_Clinician_flag'] = ((data['median_flag'] == 1) & (data['gather_flag'] == 1)).astype(int)\n",
    "                \n",
    "                action = ['No-Medication', 'Penicillin', 'Beta-lactam', 'Cephalosporin', 'Carbapenem', 'Glycopeptide', 'Selective Antimicrobial', 'Minor Antibiotic', 'Combination']\n",
    "\n",
    "                tmp = pd.DataFrame(data.query('median_flag==1').groupby('traj')['step'].min()).reset_index(drop=False)\n",
    "                tmp.rename(columns={'step':'first_flag_step'},inplace=True)\n",
    "                data = data.merge(tmp,on='traj',how='left')\n",
    "                data['first_flag'] = data['step'] - data['first_flag_step']\n",
    "                test_df_RAW = pd.read_csv(f'processed/df_{target}_RAW.csv')\n",
    "                test_df_RAW = test_df_RAW.groupby('traj', group_keys=False).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "\n",
    "                s_col = [x for x in data if x.startswith('s:') and 'prev' not in x]\n",
    "                o_col = [col.replace('s:', '') for col in s_col if 'prev' not in col]\n",
    "                data[s_col] = test_df_RAW[o_col]\n",
    "\n",
    "                negative_df = pd.merge(data, negative_traj, on='traj', how='inner')\n",
    "                negative_df['Time'] = negative_df.groupby('traj').cumcount(ascending=False).apply(lambda x: f'-{4 * (x + 1)}h')\n",
    "                negative_df_RAW = pd.merge(test_df_RAW, negative_traj, on='traj', how='inner')\n",
    "    \n",
    "                positive_df = pd.merge(data, positive_traj, on='traj', how='inner')\n",
    "                positive_df['Time'] = positive_df.groupby('traj').cumcount(ascending=False).apply(lambda x: f'-{4 * (x + 1)}h')\n",
    "                positive_df_RAW = pd.merge(test_df_RAW, positive_traj, on='traj', how='inner')\n",
    "\n",
    "                print(len(negative_df_RAW),len(negative_df))\n",
    "                print(len(positive_df_RAW),len(positive_df))\n",
    "\n",
    "                selected_steps = ['Sepsis', 'Last\\nSepsis', '-48h', '-36h', '-24h', '-12h', '-8h','-4h']\n",
    "                \n",
    "                flag_dict_res, q_values_res = compute_flag_data(positive_df, negative_df, selected_steps)\n",
    "                flag_plot(flag_dict_res, q_values_res, left_label, right_label, algorithm, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHAPModelWrapper(nn.Module):\n",
    "    def __init__(self, model, index=0):\n",
    "        super(SHAPModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.index = index\n",
    "\n",
    "    def forward(self, s):\n",
    "        q = self.model(s)\n",
    "        return q[:, :, self.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "for target in tqdm(['Dead_icu', 'Dead_hosp', 'Dead_90', 'AKI_rrt', 'AKI_48', 'AKI_24', 'AKI_12', 'Septic_shock']):\n",
    "\n",
    "    s_col = [x for x in data_dict[target]['test'] if x[:2] == 's:']\n",
    "    s_col = [x[2:] if x.startswith('s:') else x for x in s_col]\n",
    "    \n",
    "    background = data_dict[target]['test_transition'].dataset.tensors[0].to(device)\n",
    "    baseline = data_dict[target]['test_df_baseline_transition'].dataset.tensors[0].to(device)\n",
    "\n",
    "    for algorithm in (['_ddqn', '_cql', '_iql', '_bcq']): \n",
    "        for version in (['_negative', '_positive', '_both']):\n",
    "\n",
    "            if 'integrated_gradients' not in data_dict[target][algorithm][version]:\n",
    "                data_dict[target][algorithm][version]['test']['integrated_gradients'] = {}\n",
    "                data_dict[target][algorithm][version]['test']['delta'] = {}\n",
    "\n",
    "            for idx, action in enumerate(['No-Medication', 'Penicillin', 'Beta-lactam', 'Cephalosporin',\n",
    "                                            'Carbapenem', 'Glycopeptide', 'Selective Antimicrobial', 'Minor Antibiotic', 'Combination']):\n",
    "                \n",
    "                model = data_dict[target][algorithm][version]['test']['network'].to(device)\n",
    "                model.eval()\n",
    "                \n",
    "                def model_forward(input):\n",
    "                    return model(input) \n",
    "\n",
    "                ig = IntegratedGradients(model_forward)\n",
    "                \n",
    "                attr, delta = ig.attribute(background, baseline, target=idx, return_convergence_delta=True)\n",
    "                attr_mean = torch.mean(attr, dim=0).cpu().numpy()\n",
    "                data_dict[target][algorithm][version]['test']['integrated_gradients'][action] = attr_mean\n",
    "                data_dict[target][algorithm][version]['test']['delta'][action] = delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    \"No-Nephrotoxic drug\": \"No-Medication\",\n",
    "    \"Antimicrobial\": \"Selective Antimicrobial\",\n",
    "    \"Antibiotic\": \"Minor Antibiotic\"\n",
    "}\n",
    "\n",
    "for target in data_dict.keys():\n",
    "    for algorithm in ['_ddqn', '_cql', '_iql', '_bcq']:\n",
    "        for version in ['_negative', '_positive', '_both']:\n",
    "            if 'integrated_gradients' in data_dict[target][algorithm][version]['test']:\n",
    "                ig_dict = data_dict[target][algorithm][version]['test']['integrated_gradients']\n",
    "                delta_dict = data_dict[target][algorithm][version]['test']['delta']\n",
    "                \n",
    "                updated_ig_dict = {rename_map.get(k, k): v for k, v in ig_dict.items()}\n",
    "                updated_delta_dict = {rename_map.get(k, k): v for k, v in delta_dict.items()}\n",
    "                \n",
    "                data_dict[target][algorithm][version]['test']['integrated_gradients'] = updated_ig_dict\n",
    "                data_dict[target][algorithm][version]['test']['delta'] = updated_delta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['No-Medication', 'Penicillin', 'Beta-lactam','Cephalosporin', 'Carbapenem', 'Glycopeptide', 'Selective Antimicrobial', 'Minor Antibiotic', 'Combination']\n",
    "\n",
    "algorithms = ['_iql']\n",
    "versions = ['_negative', '_positive', '_both']\n",
    "\n",
    "for target in ['Dead_icu', 'Dead_hosp', 'Dead_90', 'AKI_rrt', 'AKI_48', 'AKI_24', 'AKI_12', 'Septic_shock']:\n",
    "    s_col = [x for x in data_dict[target]['train'] if x.startswith('s:')]\n",
    "    s_col = [x[2:] for x in s_col]\n",
    "\n",
    "    def replace_action_name(feature_name):\n",
    "        parts = feature_name.split('_')\n",
    "        if len(parts) == 3 and parts[0] == 'action' and parts[2] == 'prev':\n",
    "            action_idx = int(parts[1])\n",
    "            if 1 <= action_idx <= len(actions):\n",
    "                return f\"{actions[action_idx-1]}_prev\"\n",
    "        return feature_name\n",
    "    \n",
    "    s_col = [replace_action_name(x) for x in s_col]\n",
    "    s_col = [item.replace('_', ' ') for item in s_col]\n",
    "\n",
    "    def convert_subscripts(label):\n",
    "        label = label.replace('_', ' ')\n",
    "        label = re.sub(r'(\\bFiO2\\b)', r'$\\\\mathrm{FiO_2}$', label)\n",
    "        label = re.sub(r'(\\bPaO2\\b)', r'$\\\\mathrm{PaO_2}$', label)\n",
    "        label = re.sub(r'(\\bPaCO2\\b)', r'$\\\\mathrm{PaCO_2}$', label)\n",
    "        label = re.sub(r'(\\bPaO2/FiO2\\b)', r'$\\\\mathrm{PaO_2/FiO_2}$', label)\n",
    "        label = re.sub(r'(\\bSpO2\\b)', r'$\\\\mathrm{SpO_2}$', label)\n",
    "        return label\n",
    "\n",
    "    categories = [convert_subscripts(label) for label in s_col]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(algorithms),\n",
    "        ncols=len(versions),\n",
    "        figsize=(20, 20),\n",
    "        subplot_kw={'polar': True}\n",
    "    )\n",
    "\n",
    "    angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n",
    "    angles += [angles[0]]\n",
    "\n",
    "    for i, algorithm in enumerate(algorithms):\n",
    "        for j, version in enumerate(versions):\n",
    "            ax = axes[j]\n",
    "\n",
    "            local_min_val = float('inf')\n",
    "            local_max_val = float('-inf')\n",
    "            all_action_data = {}\n",
    "            for act in actions:\n",
    "                data = data_dict[target][algorithm][version]['test']['integrated_gradients'][act]\n",
    "                all_action_data[act] = data\n",
    "                local_min_val = min(local_min_val, data.min())\n",
    "                local_max_val = max(local_max_val, data.max())\n",
    "\n",
    "            if local_min_val == local_max_val:\n",
    "                local_min_val -= 1e-6\n",
    "                local_max_val += 1e-6\n",
    "\n",
    "            scaled_data_dict = {}\n",
    "            for act in actions:\n",
    "                data = all_action_data[act]\n",
    "                scaled = 2.0*(data - local_min_val)/(local_max_val - local_min_val) - 1.0\n",
    "                scaled_data_dict[act] = scaled\n",
    "\n",
    "            ax.set_ylim(-1, 1)\n",
    "\n",
    "            for idx, act in enumerate(actions):\n",
    "                scaled_data = scaled_data_dict[act]\n",
    "                plot_data = np.append(scaled_data, scaled_data[0])\n",
    "                color = plt.cm.get_cmap('tab10')(idx)\n",
    "                ax.fill(angles, plot_data, color=color, alpha=0.3)\n",
    "                ax.plot(angles, plot_data, color=color, alpha=0.8, linewidth=2.0, label=act)\n",
    "\n",
    "            label_r = 1.8\n",
    "            for k, cat in enumerate(categories):\n",
    "                theta = angles[k]\n",
    "                angle_deg = np.degrees(theta)\n",
    "                if 90 < angle_deg < 270:\n",
    "                    angle_deg += 180\n",
    "                ax.text(theta, label_r, cat, rotation=angle_deg, rotation_mode='anchor', ha='center', va='center', fontsize=8)\n",
    "\n",
    "            radial_lines = angles[:-1]\n",
    "            ax.set_xticks(radial_lines)\n",
    "            ax.set_xticklabels([''] * len(radial_lines))\n",
    "            ax.set_yticks([-1.0, -0.5, 0.0, 0.5, 1.0]) \n",
    "            ax.xaxis.grid(True, color='gray', linewidth=1.0, alpha=0.7)\n",
    "            ax.yaxis.grid(True, color='black', linewidth=1.2)\n",
    "\n",
    "            subplot_title = f\"{target} - {algorithm.replace('_', '')} - {version.replace('_', '')}\"\n",
    "            ax.set_title(subplot_title, fontsize=12, pad=70)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(\n",
    "        handles, labels,\n",
    "        loc='lower center', bbox_to_anchor=(0.5, -0.05),\n",
    "        ncol=len(actions), fontsize=12, title=\"Actions\"\n",
    "    )\n",
    "\n",
    "    fig.subplots_adjust(\n",
    "        left=0.05, right=0.95,\n",
    "        bottom=0.05, top=0.95,\n",
    "        wspace=0.05,  \n",
    "        hspace=0.8\n",
    "    )\n",
    "\n",
    "    plt.savefig(f'figure/Feature_Importance_{target}_all_algorithms_versions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "targets = ['Dead_icu', 'AKI_rrt', 'Septic_shock']\n",
    "versions = ['_negative', '_positive', '_both']\n",
    "actions = [\n",
    "    'No-Medication', 'Penicillin', 'Beta-lactam',\n",
    "    'Cephalosporin', 'Carbapenem', 'Glycopeptide',\n",
    "    'Selective Antimicrobial', 'Minor Antibiotic', 'Combination'\n",
    "]\n",
    "\n",
    "algorithm = '_iql'\n",
    "\n",
    "target_mapping = {\n",
    "    'Septic_shock': 'Shock',\n",
    "    'AKI_rrt': 'RRT',\n",
    "}\n",
    "version_mapping = {\n",
    "    '_negative': 'D-Network',\n",
    "    '_positive': 'R-Network',\n",
    "    '_both': 'C-Network'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(targets),\n",
    "    ncols=len(versions),\n",
    "    figsize=(25, 30),\n",
    "    subplot_kw={'polar': True}\n",
    ")\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    s_col = [x for x in data_dict[target]['train'] if x.startswith('s:')]\n",
    "    s_col = [x[2:] for x in s_col]\n",
    "\n",
    "    def replace_action_name(feature_name):\n",
    "        parts = feature_name.split('_')\n",
    "        if len(parts) == 3 and parts[0] == 'action' and parts[2] == 'prev':\n",
    "            action_idx = int(parts[1])\n",
    "            if 1 <= action_idx <= len(actions):\n",
    "                return f\"{actions[action_idx-1]}_prev\"\n",
    "        return feature_name\n",
    "    \n",
    "    s_col = [replace_action_name(x) for x in s_col]\n",
    "    s_col = [item.replace('_', ' ') for item in s_col]\n",
    "\n",
    "    def convert_subscripts(label):\n",
    "        label = re.sub(r'(\\bFiO2\\b)', r'$\\\\mathrm{FiO_2}$', label)\n",
    "        label = re.sub(r'(\\bPaO2\\b)', r'$\\\\mathrm{PaO_2}$', label)\n",
    "        label = re.sub(r'(\\bPaCO2\\b)', r'$\\\\mathrm{PaCO_2}$', label)\n",
    "        label = re.sub(r'(\\bPaO2/FiO2\\b)', r'$\\\\mathrm{PaO_2/FiO_2}$', label)\n",
    "        label = re.sub(r'(\\bSpO2\\b)', r'$\\\\mathrm{SpO_2}$', label)\n",
    "        return label\n",
    "\n",
    "    s_col = [sc[0].upper() + sc[1:] if sc else sc for sc in s_col]\n",
    "    categories = [convert_subscripts(x) for x in s_col]\n",
    "\n",
    "    angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))\n",
    "\n",
    "    for j, version in enumerate(versions):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        local_min_val = float('inf')\n",
    "        local_max_val = float('-inf')\n",
    "        all_action_data = {}\n",
    "\n",
    "        for act in actions:\n",
    "            data = data_dict[target][algorithm][version]['test']['integrated_gradients'][act]\n",
    "            all_action_data[act] = data\n",
    "            local_min_val = min(local_min_val, data.min())\n",
    "            local_max_val = max(local_max_val, data.max())\n",
    "\n",
    "        if local_min_val == local_max_val:\n",
    "            local_min_val -= 1e-6\n",
    "            local_max_val += 1e-6\n",
    "\n",
    "        scaled_data_dict = {}\n",
    "        for act in actions:\n",
    "            raw_data = all_action_data[act]\n",
    "            scaled = 2.0 * (raw_data - local_min_val) / (local_max_val - local_min_val) - 1.0\n",
    "            scaled_data_dict[act] = scaled\n",
    "\n",
    "        ax.set_ylim(-1, 1)\n",
    "\n",
    "        for idx, act in enumerate(actions):\n",
    "            scaled_data = scaled_data_dict[act]\n",
    "            plot_data = np.append(scaled_data, scaled_data[0])\n",
    "            color = plt.cm.get_cmap('tab10')(idx)\n",
    "            ax.fill(angles, plot_data, color=color, alpha=0.3)\n",
    "            ax.plot(angles, plot_data, color=color, alpha=0.8, linewidth=2.0,\n",
    "                    label=act if (i == 0 and j == 0) else None)\n",
    "\n",
    "        label_r = 1.8\n",
    "        for k, cat in enumerate(categories):\n",
    "            theta = angles[k]\n",
    "            angle_deg = np.degrees(theta)\n",
    "            if 90 < angle_deg < 270:\n",
    "                angle_deg += 180\n",
    "            ax.text(\n",
    "                theta, label_r, cat,\n",
    "                rotation=angle_deg, rotation_mode='anchor',\n",
    "                ha='center', va='center', fontsize=10\n",
    "            )\n",
    "\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels([''] * (len(angles)-1))\n",
    "        ax.set_yticks([-1.0, -0.5, 0.0, 0.5, 1.0])\n",
    "        ax.xaxis.grid(True, color='gray', linewidth=1.0, alpha=0.7)\n",
    "        ax.yaxis.grid(True, color='black', linewidth=1.2)\n",
    "\n",
    "        display_target = target_mapping.get(target, target)\n",
    "        display_version = version_mapping.get(version, version)\n",
    "        subplot_title = f\"{display_target} - {display_version}\"\n",
    "        ax.set_title(\n",
    "            subplot_title,\n",
    "            fontsize=14,\n",
    "            pad=15\n",
    "        )\n",
    "\n",
    "handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "fig.legend(\n",
    "    handles, labels,\n",
    "    loc='lower center',\n",
    "    bbox_to_anchor=(0.5, -0.02),\n",
    "    ncol=len(actions),\n",
    "    fontsize=15,\n",
    "    title=\"Actions\",\n",
    "    title_fontsize=20\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(\n",
    "    left=0.05,\n",
    "    right=0.95,\n",
    "    bottom=0.05,\n",
    "    top=0.90,\n",
    "    wspace=0.6,\n",
    "    hspace=0.20\n",
    ")\n",
    "\n",
    "plt.savefig(\"figure/sensitivity_investigation.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advise against A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch, Rectangle\n",
    "import colorsys\n",
    "from matplotlib.colors import to_rgb\n",
    "\n",
    "def set_saturation(base_color, new_saturation):\n",
    "    r, g, b = base_color\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    s = new_saturation\n",
    "    r2, g2, b2 = colorsys.hls_to_rgb(h, l, s)\n",
    "    return (r2, g2, b2)\n",
    "\n",
    "def percent_to_saturation(p):\n",
    "    sat_min, sat_max = 0.3, 1.0\n",
    "    alpha = 1.0\n",
    "    t = (p/100.0)**alpha\n",
    "    sat = sat_min + t*(sat_max - sat_min)\n",
    "    return sat\n",
    "\n",
    "def advise_against_A(positive_df, negative_df, action_stats, left_label, right_label, algorithm, threshold):\n",
    "    base_colors = {\n",
    "        'positive': to_rgb('blue'),\n",
    "        'negative': to_rgb('red'),\n",
    "        'both':     to_rgb('green'),\n",
    "        'combination': to_rgb('yellow'),\n",
    "    }\n",
    "\n",
    "    label_colors = {\n",
    "        'positive': 'blue',\n",
    "        'negative': 'red',\n",
    "        'both': 'green',\n",
    "        'combination': 'yellow'\n",
    "    }\n",
    "    legend_handles = [\n",
    "        Patch(facecolor=label_colors['positive'],    edgecolor='k', label='R-network'),\n",
    "        Patch(facecolor=label_colors['negative'],    edgecolor='k', label='D-network'),\n",
    "        Patch(facecolor=label_colors['both'],        edgecolor='k', label='C-network'),\n",
    "        Patch(facecolor=label_colors['combination'], edgecolor='k', label='Full')\n",
    "    ]\n",
    "\n",
    "    action = [\n",
    "        'No-Medication', 'Cephalosporin', 'Glycopeptide',\n",
    "        'Beta-lactam', 'Carbapenem', 'Penicillin',\n",
    "        'Minor Antibiotic', 'Selective Antimicrobial', 'Combination'\n",
    "    ]\n",
    "    \n",
    "    n_action = len(action)\n",
    "\n",
    "    max_count_positive = len(positive_df)\n",
    "    max_count_negative = len(negative_df)\n",
    "    max_count_diagonal = max_count_positive + max_count_negative\n",
    "\n",
    "    for i in range(n_action):\n",
    "        for j in range(n_action):\n",
    "            key = f'{action[i]}-{action[j]}'\n",
    "            if key not in action_stats:\n",
    "                continue\n",
    "\n",
    "            c_pos_p  = action_stats[key]['positive']['count_positive']\n",
    "            c_neg_p  = action_stats[key]['positive']['count_negative']\n",
    "            c_both_p = action_stats[key]['positive']['count_both']\n",
    "            c_comb_p = action_stats[key]['positive']['count_combination']\n",
    "\n",
    "            c_pos_n  = action_stats[key]['negative']['count_positive']\n",
    "            c_neg_n  = action_stats[key]['negative']['count_negative']\n",
    "            c_both_n = action_stats[key]['negative']['count_both']\n",
    "            c_comb_n = action_stats[key]['negative']['count_combination']\n",
    "\n",
    "            pos_max = max(c_pos_p, c_neg_p, c_both_p, c_comb_p)\n",
    "            neg_max = max(c_pos_n, c_neg_n, c_both_n, c_comb_n)\n",
    "\n",
    "            if i < j:\n",
    "                if pos_max > max_count_positive:\n",
    "                    max_count_positive = pos_max\n",
    "            elif i > j:\n",
    "                if neg_max > max_count_negative:\n",
    "                    max_count_negative = neg_max\n",
    "            else:\n",
    "                c_pos_d  = c_pos_p  + c_pos_n\n",
    "                c_neg_d  = c_neg_p  + c_neg_n\n",
    "                c_both_d = c_both_p + c_both_n\n",
    "                c_comb_d = c_comb_p + c_comb_n\n",
    "                diag_max = max(c_pos_d, c_neg_d, c_both_d, c_comb_d)\n",
    "                if diag_max > max_count_diagonal:\n",
    "                    max_count_diagonal = diag_max\n",
    "\n",
    "    if max_count_positive == 0:\n",
    "        max_count_positive = 1e-9\n",
    "    if max_count_negative == 0:\n",
    "        max_count_negative = 1e-9\n",
    "    if max_count_diagonal == 0:\n",
    "        max_count_diagonal = 1e-9\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    fig.suptitle(\n",
    "        f'{left_label}(upper) vs. {right_label}(lower)',\n",
    "        fontsize=20, fontweight='bold', y=0.95\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(0, n_action)\n",
    "    ax.set_ylim(0, n_action)\n",
    "\n",
    "    ax.set_xticks(np.arange(n_action) + 0.5)\n",
    "    ax.set_yticks(np.arange(n_action) + 0.5)\n",
    "    ax.set_xticklabels(action, rotation=90, ha='center', va='top', fontsize=12)\n",
    "    ax.set_yticklabels(action, fontsize=12)\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    ax.tick_params(axis='x', pad=2)\n",
    "\n",
    "    ax.spines['top'].set_zorder(0)\n",
    "    ax.spines['bottom'].set_zorder(0)\n",
    "    ax.spines['left'].set_zorder(0)\n",
    "    ax.spines['right'].set_zorder(0)\n",
    "    ax.set_axisbelow(False)\n",
    "\n",
    "    if target == 'Septic_shock':\n",
    "        fig.legend(\n",
    "            handles=legend_handles,\n",
    "            loc='lower center',\n",
    "            bbox_to_anchor=(0.6, 0.01),\n",
    "            ncol=4,\n",
    "            frameon=True,\n",
    "            fontsize=18\n",
    "        )\n",
    "\n",
    "    ax.plot([0, n_action], [0, n_action], color='black', linewidth=2, zorder=0, alpha=0.3)\n",
    "\n",
    "    for i in range(n_action):\n",
    "        for j in range(n_action):\n",
    "            key = f'{action[i]}-{action[j]}'\n",
    "            if key not in action_stats:\n",
    "                continue\n",
    "\n",
    "            c_pos_p  = action_stats[key]['positive']['count_positive']\n",
    "            c_neg_p  = action_stats[key]['positive']['count_negative']\n",
    "            c_both_p = action_stats[key]['positive']['count_both']\n",
    "            c_comb_p = action_stats[key]['positive']['count_combination']\n",
    "\n",
    "            c_pos_n  = action_stats[key]['negative']['count_positive']\n",
    "            c_neg_n  = action_stats[key]['negative']['count_negative']\n",
    "            c_both_n = action_stats[key]['negative']['count_both']\n",
    "            c_comb_n = action_stats[key]['negative']['count_combination']\n",
    "\n",
    "            x0, y0 = j, i\n",
    "            cell_w = 1.0\n",
    "            cell_h = 1.0\n",
    "\n",
    "            if i < j:\n",
    "                local_max = max_count_positive\n",
    "                c_pos  = c_pos_p\n",
    "                c_neg  = c_neg_p\n",
    "                c_both = c_both_p\n",
    "                c_comb = c_comb_p\n",
    "            elif i > j:\n",
    "                local_max = max_count_negative\n",
    "                c_pos  = c_pos_n\n",
    "                c_neg  = c_neg_n\n",
    "                c_both = c_both_n\n",
    "                c_comb = c_comb_n\n",
    "            else:\n",
    "                local_max = max_count_diagonal\n",
    "                c_pos  = c_pos_p  + c_pos_n\n",
    "                c_neg  = c_neg_p  + c_neg_n\n",
    "                c_both = c_both_p + c_both_n\n",
    "                c_comb = c_comb_p + c_comb_n\n",
    "                x0 = x0 + 0.075\n",
    "                y0 = y0 + 0.075\n",
    "                cell_w = 0.85\n",
    "                cell_h = 0.85\n",
    "\n",
    "            p_pos  = (c_pos  / local_max)*100.0\n",
    "            p_neg  = (c_neg  / local_max)*100.0\n",
    "            p_both = (c_both / local_max)*100.0\n",
    "            p_comb = (c_comb / local_max)*100.0\n",
    "\n",
    "            alpha_pos  = percent_to_saturation(p_pos)\n",
    "            alpha_neg  = percent_to_saturation(p_neg)\n",
    "            alpha_both = percent_to_saturation(p_both)\n",
    "            alpha_comb = percent_to_saturation(p_comb)\n",
    "\n",
    "            sat_pos  = percent_to_saturation(p_pos)\n",
    "            sat_neg  = percent_to_saturation(p_neg)\n",
    "            sat_both = percent_to_saturation(p_both)\n",
    "            sat_comb = percent_to_saturation(p_comb)\n",
    "\n",
    "            color_pos  = set_saturation(base_colors['positive'], sat_pos)\n",
    "            color_neg  = set_saturation(base_colors['negative'], sat_neg)\n",
    "            color_both = set_saturation(base_colors['both'],     sat_both)\n",
    "            color_comb = set_saturation(base_colors['combination'], sat_comb)\n",
    "\n",
    "            rect_tl = Rectangle((x0, y0), 0.5*cell_w, 0.5*cell_h,\n",
    "                                facecolor=color_pos, \n",
    "                                edgecolor='k', linewidth=0.7, alpha=alpha_pos, zorder=10)\n",
    "            ax.add_patch(rect_tl)\n",
    "            ax.text(x0+0.25*cell_w, y0+0.25*cell_h, f\"{p_pos:.1f}%\", ha='center', va='center',\n",
    "                    fontsize=9, color='black', zorder=11)\n",
    "\n",
    "            rect_tr = Rectangle((x0+0.5*cell_w, y0), 0.5*cell_w, 0.5*cell_h,\n",
    "                                facecolor=color_neg, \n",
    "                                edgecolor='k', linewidth=0.7, alpha=alpha_neg, zorder=10)\n",
    "            ax.add_patch(rect_tr)\n",
    "            ax.text(x0+0.75*cell_w, y0+0.25*cell_h, f\"{p_neg:.1f}%\", ha='center', va='center',\n",
    "                    fontsize=9, color='black', zorder=11)\n",
    "\n",
    "            rect_bl = Rectangle((x0, y0+0.5*cell_h), 0.5*cell_w, 0.5*cell_h,\n",
    "                                facecolor=color_both, \n",
    "                                edgecolor='k', linewidth=0.7, alpha=alpha_both, zorder=10)\n",
    "            ax.add_patch(rect_bl)\n",
    "            ax.text(x0+0.25*cell_w, y0+0.75*cell_h, f\"{p_both:.1f}%\", ha='center', va='center',\n",
    "                    fontsize=9, color='black', zorder=11)\n",
    "\n",
    "            rect_br = Rectangle((x0+0.5*cell_w, y0+0.5*cell_h), 0.5*cell_w, 0.5*cell_h,\n",
    "                                facecolor=color_comb, \n",
    "                                edgecolor='k', linewidth=0.7, alpha=alpha_comb, zorder=10)\n",
    "            ax.add_patch(rect_br)\n",
    "            ax.text(x0+0.75*cell_w, y0+0.75*cell_h, f\"{p_comb:.1f}%\", ha='center', va='center',\n",
    "                    fontsize=9, color='black', zorder=11)\n",
    "\n",
    "            cell_border = Rectangle((x0, y0), cell_w, cell_h,\n",
    "                                    fill=False, edgecolor='black', linewidth=2, zorder=12)\n",
    "            ax.add_patch(cell_border)\n",
    "\n",
    "    outer_rect = Rectangle((0,0), n_action, n_action,\n",
    "                           fill=False, edgecolor='black', linewidth=4, zorder=15)\n",
    "    ax.add_patch(outer_rect)\n",
    "\n",
    "    ax.set_xticks(np.arange(n_action), minor=True)\n",
    "    ax.set_yticks(np.arange(n_action), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"gray\", linestyle=':', linewidth=0.5, zorder=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.savefig(f'figure/advise_against_A_heatmap_{right_label}{algorithm}_{threshold}.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in tqdm(['Dead_icu', 'AKI_rrt', 'Septic_shock']):\n",
    "\n",
    "    data = pd.read_csv(f'processed/df_{target}.csv', index_col=0)\n",
    "\n",
    "    if 'Septic' in target : reward = 'r:reward_septic_shock'\n",
    "    elif 'Dead' in target : reward = 'r:reward_dead'\n",
    "    else : reward = 'r:reward_aki'\n",
    "\n",
    "    if 'Dead' in target:\n",
    "        left_label, right_label = 'Discharge', target\n",
    "    elif 'rrt' in target:\n",
    "        left_label, right_label = 'No-RRT', 'RRT'\n",
    "    elif 'AKI' in target:\n",
    "        left_label, right_label = 'Nn-C'+target, 'C'+target\n",
    "    elif 'Septic' in target:\n",
    "        left_label, right_label = 'No-Shock', 'Shock'\n",
    "    else:\n",
    "        left_label, right_label = 'Positive', 'Negative'\n",
    "\n",
    "    for algorithm in ['_iql']:\n",
    "\n",
    "        for threshold in ['threshold_p']:\n",
    "\n",
    "            unique_conditions = np.unique(data_dict[target]['test'][reward])\n",
    "\n",
    "            positive_traj = data_dict[target]['test'].groupby('traj').filter(lambda x: x.iloc[-1][reward] in [max(unique_conditions)])['traj'].drop_duplicates().reset_index(drop=True)\n",
    "            negative_traj = data_dict[target]['test'].groupby('traj').filter(lambda x: x.iloc[-1][reward] in [min(unique_conditions)])['traj'].drop_duplicates().reset_index(drop=True)\n",
    "            data = data_dict[target]['test'].groupby('traj', group_keys=False).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "\n",
    "            negative_df = pd.merge(data, negative_traj, on='traj', how='inner')\n",
    "            positive_df = pd.merge(data, positive_traj, on='traj', how='inner')\n",
    "\n",
    "            action_stats = {}\n",
    "\n",
    "            action = [\n",
    "                'No-Medication', 'Cephalosporin', 'Glycopeptide',\n",
    "                'Beta-lactam', 'Carbapenem', 'Penicillin',\n",
    "                'Minor Antibiotic', 'Selective Antimicrobial', 'Combination'\n",
    "    ]\n",
    "\n",
    "            def calculate_action_stats(df, treatment_A, treatment_B):\n",
    "                stats = {}\n",
    "                for label in ['positive', 'negative', 'both', 'combination']:\n",
    "\n",
    "                    count = df.loc[\n",
    "                        (df[f'advise_againt_{treatment_A}_{label}'] == 1) & \n",
    "                        (df[f'advise_againt_{treatment_B}_{label}'] == 1),\n",
    "                        f'advise_againt_{treatment_A}_{label}'\n",
    "                    ].sum()\n",
    "\n",
    "                    mean = round(\n",
    "                    df.loc[\n",
    "                        (df[f'advise_againt_{treatment_A}_{label}'] == 1) & \n",
    "                        (df[f'advise_againt_{treatment_B}_{label}'] == 1),\n",
    "                        treatment_A\n",
    "                    ].mean() * 100, 1\n",
    "                )\n",
    "\n",
    "                    stats[f'count_{label}'] = count\n",
    "                    stats[f'mean_{label}'] = mean\n",
    "\n",
    "                return stats\n",
    "\n",
    "            for idx, treatment_A in enumerate(action):\n",
    "                for jdx, treatment_B in enumerate(action):\n",
    "\n",
    "                    for label in ['positive', 'negative', 'both']:\n",
    "                        data[f'advise_againt_{treatment_A}_{label}'] = (\n",
    "                            (data_dict[target][algorithm][f'_{label}']['test']['q_value'][:,idx] <= \n",
    "                            data_dict[target][algorithm][f'_{label}']['test']['thresholds'][threshold+'_med'])\n",
    "                        ).astype(int)\n",
    "\n",
    "                        data[f'advise_againt_{treatment_B}_{label}'] = (\n",
    "                            (data_dict[target][algorithm][f'_{label}']['test']['q_value'][:,jdx] <= \n",
    "                            data_dict[target][algorithm][f'_{label}']['test']['thresholds'][threshold+'_med'])\n",
    "                        ).astype(int)\n",
    "\n",
    "                        data[f'{treatment_A}'] = data_dict[target][algorithm][f'_{label}']['test']['q_value'][:,idx]\n",
    "                        data[f'{treatment_B}'] = data_dict[target][algorithm][f'_{label}']['test']['q_value'][:,jdx]\n",
    "\n",
    "                    data[f'advise_againt_{treatment_A}_combination'] = (\n",
    "                        (data_dict[target][algorithm]['_positive']['test']['q_value'][:,idx] <= \n",
    "                        data_dict[target][algorithm]['_positive']['test']['thresholds'][threshold+'_med']) &\n",
    "                        (data_dict[target][algorithm]['_negative']['test']['q_value'][:,idx] <= \n",
    "                        data_dict[target][algorithm]['_negative']['test']['thresholds'][threshold+'_med'])\n",
    "                    ).astype(int)\n",
    "\n",
    "                    data[f'advise_againt_{treatment_B}_combination'] = (\n",
    "                        (data_dict[target][algorithm]['_positive']['test']['q_value'][:,jdx] <= \n",
    "                        data_dict[target][algorithm]['_positive']['test']['thresholds'][threshold+'_med']) &\n",
    "                        (data_dict[target][algorithm]['_negative']['test']['q_value'][:,jdx] <= \n",
    "                        data_dict[target][algorithm]['_negative']['test']['thresholds'][threshold+'_med'])\n",
    "                    ).astype(int)\n",
    "\n",
    "                    positive_df = pd.merge(data, positive_traj, on='traj', how='inner')\n",
    "                    negative_df = pd.merge(data, negative_traj, on='traj', how='inner')\n",
    "\n",
    "                    action_stats[f'{treatment_A}-{treatment_B}'] = {\n",
    "                        'positive': calculate_action_stats(positive_df, treatment_A, treatment_B),\n",
    "                        'negative': calculate_action_stats(negative_df, treatment_A, treatment_B)\n",
    "                    }           \n",
    "\n",
    "            advise_against_A(positive_df, negative_df, action_stats, left_label, right_label, algorithm, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trajectory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm, to_rgba\n",
    "\n",
    "ACTION_LIST = [\n",
    "    'No-Medication',\n",
    "    'Penicillin',\n",
    "    'Beta-lactam',\n",
    "    'Cephalosporin',\n",
    "    'Carbapenem',\n",
    "    'Glycopeptide',\n",
    "    'Selective Antimicrobial',\n",
    "    'Minor Antibiotic',\n",
    "    'Combination'\n",
    "]\n",
    "n_drug = len(ACTION_LIST)\n",
    "\n",
    "def combine_three_targets_into_array(df_dead, df_aki, df_ss, action_list):\n",
    "    steps = df_dead['step'].values\n",
    "    T = len(steps)\n",
    "    data_full = np.full((25, T), np.nan)\n",
    "    data_full[0, :] = df_dead['q_negative_median'].to_numpy()\n",
    "    data_full[1, :] = df_dead['q_negative_gather'].to_numpy()\n",
    "    data_full[2, :] = df_dead['q_positive_median'].to_numpy()\n",
    "    data_full[3, :] = df_dead['q_positive_gather'].to_numpy()\n",
    "    data_full[4, :] = df_aki['q_negative_median'].to_numpy()\n",
    "    data_full[5, :] = df_aki['q_negative_gather'].to_numpy()\n",
    "    data_full[6, :] = df_aki['q_positive_median'].to_numpy()\n",
    "    data_full[7, :] = df_aki['q_positive_gather'].to_numpy()\n",
    "    data_full[8, :]  = df_ss['q_negative_median'].to_numpy()\n",
    "    data_full[9, :]  = df_ss['q_negative_gather'].to_numpy()\n",
    "    data_full[10, :] = df_ss['q_positive_median'].to_numpy()\n",
    "    data_full[11, :] = df_ss['q_positive_gather'].to_numpy()\n",
    "    data_full[12, :] = df_dead['a:action'].to_numpy()\n",
    "    data_full[13, :] = df_dead['AKI_max_stage'].to_numpy()\n",
    "    for i, drug_name in enumerate(action_list):\n",
    "        row_idx = 14 + i\n",
    "        dead_adv = (((df_dead[f'advise_againt_{drug_name}_negative'].values == 1) |\n",
    "                     (df_dead[f'advise_againt_{drug_name}_positive'].values == 1)).astype(int))\n",
    "        aki_adv = (((df_aki[f'advise_againt_{drug_name}_negative'].values == 1) |\n",
    "                    (df_aki[f'advise_againt_{drug_name}_positive'].values == 1)).astype(int))\n",
    "        ss_adv = (((df_ss[f'advise_againt_{drug_name}_negative'].values == 1) |\n",
    "                   (df_ss[f'advise_againt_{drug_name}_positive'].values == 1)).astype(int))\n",
    "        data_full[row_idx, :] = (dead_adv << 2) | (aki_adv << 1) | ss_adv\n",
    "    median_flag_combined = (df_dead['median_flag'].to_numpy() << 2) | \\\n",
    "                           (df_aki['median_flag'].to_numpy() << 1) | \\\n",
    "                           (df_ss['median_flag'].to_numpy())\n",
    "    gather_flag_combined = (df_dead['gather_flag'].to_numpy() << 2) | \\\n",
    "                           (df_aki['gather_flag'].to_numpy() << 1) | \\\n",
    "                           (df_ss['gather_flag'].to_numpy())\n",
    "    data_full[23, :] = median_flag_combined\n",
    "    data_full[24, :] = gather_flag_combined\n",
    "    return data_full, steps\n",
    "\n",
    "def plot_combined_heatmap(data_full, steps, df_ss=None, action_list=ACTION_LIST,\n",
    "                          traj_id='', threshold_list=None, threshold='threshold_p',\n",
    "                          figsize=(12, 10), dataset='test', algorithm='_ddqn'):\n",
    "    n_rows, T = data_full.shape\n",
    "    if (threshold_list is not None) and (len(threshold_list) == 6):\n",
    "        thr_pos_dead, thr_neg_dead, thr_pos_aki, thr_neg_aki, thr_pos_ss, thr_neg_ss = threshold_list\n",
    "    else:\n",
    "        thr_pos_dead = thr_neg_dead = thr_pos_aki = thr_neg_aki = thr_pos_ss = thr_neg_ss = None\n",
    "    def _fmt_thr(x):\n",
    "        if x is None: return '-'\n",
    "        s = f\"{x:.2f}\"\n",
    "        return s.rstrip('0').rstrip('.')\n",
    "    title_str = (\n",
    "        f\"Traj={traj_id} | {algorithm} | Combined(Dead,AKI,SS) | \"\n",
    "        f\"thr(pos)={[ _fmt_thr(thr_pos_dead), _fmt_thr(thr_pos_aki), _fmt_thr(thr_pos_ss) ]}, \"\n",
    "        f\"thr(neg)={[ _fmt_thr(thr_neg_dead), _fmt_thr(thr_neg_aki), _fmt_thr(thr_neg_ss) ]}\"\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    mask_q = np.ones_like(data_full, dtype=bool)\n",
    "    mask_q[0:12, :] = False\n",
    "    sns.heatmap(data_full, mask=mask_q, cmap='plasma', vmin=-1, vmax=1,\n",
    "                annot=True, fmt='.2f', linewidths=1, linecolor='white',\n",
    "                cbar=False, xticklabels=False, yticklabels=False, ax=ax)\n",
    "    mask_treat = np.ones_like(data_full, dtype=bool)\n",
    "    mask_treat[12, :] = False\n",
    "    data_treatment = np.zeros_like(data_full)\n",
    "    annot_treat = np.full(data_full.shape, '', dtype=object)\n",
    "    for c in range(T):\n",
    "        annot_treat[12, c] = str(int(data_full[12, c]))\n",
    "    sns.heatmap(data_treatment, mask=mask_treat, cmap=['black'], annot=annot_treat,\n",
    "                fmt='s', cbar=False, linewidths=1, linecolor='white',\n",
    "                xticklabels=False, yticklabels=False, ax=ax)\n",
    "    mask_treat = np.ones_like(data_full, dtype=bool)\n",
    "    mask_treat[13, :] = False\n",
    "    data_treatment = np.zeros_like(data_full)\n",
    "    annot_treat = np.full(data_full.shape, '', dtype=object)\n",
    "    for c in range(T):\n",
    "        annot_treat[13, c] = str(int(data_full[13, c]))\n",
    "    sns.heatmap(data_treatment, mask=mask_treat, cmap=[\"#ffd54f\"], annot=annot_treat,\n",
    "                fmt='s', cbar=False, linewidths=1, linecolor='white',\n",
    "                xticklabels=False, yticklabels=False, ax=ax)\n",
    "    mask_advise = np.ones_like(data_full, dtype=bool)\n",
    "    mask_advise[14:14+n_drug, :] = False\n",
    "    boundaries = np.arange(9)\n",
    "    norm_advise = BoundaryNorm(boundaries, ncolors=8, clip=True)\n",
    "    advise_cmap = ListedColormap([\n",
    "        to_rgba(\"#e0f7da\", alpha=0.8), \"#ffcc80\", \"#ffd54f\", \"#ff9800\",\n",
    "        \"#ff8a80\", \"#d50000\", \"#a70000\", \"#000000\",\n",
    "    ])\n",
    "    g_advise = sns.heatmap(data_full, mask=mask_advise, cmap=advise_cmap,\n",
    "                           norm=norm_advise, cbar=True,\n",
    "                           cbar_kws={'boundaries': boundaries, 'ticks': np.arange(8) + 0.5,\n",
    "                                     'spacing': 'uniform'},\n",
    "                           linewidths=1, linecolor='grey',\n",
    "                           xticklabels=False, yticklabels=False, ax=ax)\n",
    "    cbar_ax = g_advise.figure.axes[-1]\n",
    "    cbar_ax.yaxis.set_ticks(np.arange(8) + 0.5)\n",
    "    cbar_ax.yaxis.set_ticklabels([\"No\", \"SS\", \"AKI\", \"AKI+SS\",\n",
    "                                  \"Dead\", \"Dead+SS\", \"Dead+AKI\", \"Dead+AKI+SS\"])\n",
    "    cbar_ax.tick_params(labelsize=9)\n",
    "    mask_flag = np.ones_like(data_full, dtype=bool)\n",
    "    mask_flag[23:25, :] = False\n",
    "    flag_cmap = ListedColormap([\n",
    "        to_rgba(\"#e0f7da\", alpha=0.8), \"#ffcc80\", \"#ffd54f\", \"#ff9800\",\n",
    "        \"#ff8a80\", \"#e53935\", \"#d32f2f\", \"#000000\",\n",
    "    ])\n",
    "    sns.heatmap(data_full, mask=mask_flag, cmap=flag_cmap, norm=norm_advise,\n",
    "                cbar=False, linewidths=1, linecolor='white',\n",
    "                xticklabels=False, yticklabels=False, ax=ax)\n",
    "    ax.set_xticks([i+0.5 for i in range(T)])\n",
    "    x_tick_labels = [str(s) for s in steps]\n",
    "    if df_ss is not None and ('sepsis' in df_ss.columns):\n",
    "        sepsis_df = df_ss[df_ss['sepsis'] == 1].copy()\n",
    "        if not sepsis_df.empty:\n",
    "            sepsis_df = sepsis_df.sort_values('step')\n",
    "            first_step = sepsis_df['step'].iloc[0]\n",
    "            if first_step in steps:\n",
    "                i_f = np.where(steps == first_step)[0][0]\n",
    "                x_tick_labels[i_f] += r\"$^{F}$\"\n",
    "    ax.set_xticklabels(x_tick_labels, rotation=0)\n",
    "    ylabels = [\n",
    "        r'$V_{D}^{Dead}$', r'$Q_{D}^{Dead}$', r'$V_{R}^{Dead}$', r'$Q_{R}^{Dead}$',\n",
    "        r'$V_{D}^{AKI}$', r'$Q_{D}^{AKI}$', r'$V_{R}^{AKI}$', r'$Q_{R}^{AKI}$',\n",
    "        r'$V_{D}^{SS}$', r'$Q_{D}^{SS}$', r'$V_{R}^{SS}$', r'$Q_{R}^{SS}$',\n",
    "        'Treatment', r'$AKI_{stage}$'\n",
    "    ]\n",
    "    for i in range(n_drug):\n",
    "        ylabels.append(f\"Advise: {i+1}\")\n",
    "    ylabels += [r'$V_{flag}$', r'$Q_{flag}$']\n",
    "    ax.set_yticks([i+0.5 for i in range(n_rows)])\n",
    "    ax.set_yticklabels(ylabels, rotation=0)\n",
    "    ax.set_title(title_str, fontsize=12, pad=10)\n",
    "    ax.set_xlabel(\"Time (step=4hrs)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figure/traj_{dataset}/{traj_id}{algorithm}_{threshold}.png\",\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def attach_flags_and_advise(data, data_dict, target, algorithm, threshold, dataset):\n",
    "    data['q_negative_median'] = data_dict[target][algorithm]['_negative'][dataset]['q_median'].round(2)\n",
    "    data['q_positive_median'] = data_dict[target][algorithm]['_positive'][dataset]['q_median'].round(2)\n",
    "    data['q_negative_gather'] = data_dict[target][algorithm]['_negative'][dataset]['q_gather'].round(2)\n",
    "    data['q_positive_gather'] = data_dict[target][algorithm]['_positive'][dataset]['q_gather'].round(2)\n",
    "\n",
    "    data['median_flag'] = (\n",
    "        (data_dict[target][algorithm]['_positive'][dataset]['q_median']\n",
    "         <= data_dict[target][algorithm]['_positive'][dataset]['thresholds'][threshold+'_med'])\n",
    "        &\n",
    "        (data_dict[target][algorithm]['_negative'][dataset]['q_median']\n",
    "         <= data_dict[target][algorithm]['_negative'][dataset]['thresholds'][threshold+'_med'])\n",
    "    ).astype(int)\n",
    "\n",
    "    data['gather_flag'] = (\n",
    "        (data_dict[target][algorithm]['_positive'][dataset]['q_gather']\n",
    "         <= data_dict[target][algorithm]['_positive'][dataset]['thresholds'][threshold+'_gat'])\n",
    "        &\n",
    "        (data_dict[target][algorithm]['_negative'][dataset]['q_gather']\n",
    "         <= data_dict[target][algorithm]['_negative'][dataset]['thresholds'][threshold+'_gat'])\n",
    "    ).astype(int)\n",
    "\n",
    "    actions = [\n",
    "        'No-Medication', 'Penicillin', 'Beta-lactam', 'Cephalosporin',\n",
    "        'Carbapenem', 'Glycopeptide', 'Selective Antimicrobial', 'Minor Antibiotic', 'Combination'\n",
    "    ]\n",
    "    for idx, treatment in enumerate(actions):\n",
    "        for label in ['positive', 'negative']:\n",
    "            data[f'advise_againt_{treatment}_{label}'] = (\n",
    "                data_dict[target][algorithm][f'_{label}'][dataset]['q_value'][:, idx]\n",
    "                <= data_dict[target][algorithm][f'_{label}'][dataset]['thresholds'][threshold+'_med']\n",
    "            ).astype(int)\n",
    "            data[f'{treatment}'] = data_dict[target][algorithm][f'_{label}'][dataset]['q_value'][:, idx]\n",
    "\n",
    "        data[f'advise_againt_{treatment}_combination'] = (\n",
    "            (data_dict[target][algorithm]['_positive'][dataset]['q_value'][:, idx]\n",
    "             <= data_dict[target][algorithm]['_positive'][dataset]['thresholds'][threshold+'_med'])\n",
    "            &\n",
    "            (data_dict[target][algorithm]['_negative'][dataset]['q_value'][:, idx]\n",
    "             <= data_dict[target][algorithm]['_negative'][dataset]['thresholds'][threshold+'_med'])\n",
    "        ).astype(int)\n",
    "\n",
    "    return data\n",
    "\n",
    "def fails_filter_conditions(df_traj):\n",
    "    if df_traj['q_positive_median'].iloc[0] <= df_traj['q_positive_median'].iloc[-1]:\n",
    "        return True\n",
    "    if df_traj['q_negative_median'].iloc[0] <= df_traj['q_negative_median'].iloc[-1]:\n",
    "        return True\n",
    "    if len(df_traj) < 3:\n",
    "        return True\n",
    "    for flag in ['median_flag', 'gather_flag']:\n",
    "        count_ones = (df_traj[flag] == 1).sum()\n",
    "        length = len(df_traj[flag])\n",
    "        if (count_ones == length) or (count_ones == 0):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def run_pipeline(data_dict, dataset):\n",
    "    for algorithm in tqdm(['_iql']):\n",
    "        for threshold in ['threshold_p']:\n",
    "            dead_traj = data_dict['Dead_icu'][dataset].groupby('traj')\\\n",
    "                .filter(lambda x: x.iloc[-1]['r:reward_dead'] == -1)['traj'].drop_duplicates()\n",
    "            aki_traj = data_dict['AKI_rrt'][dataset].groupby('traj')\\\n",
    "                .filter(lambda x: x.iloc[-1]['r:reward_aki'] == -1)['traj'].drop_duplicates()\n",
    "            ss_traj  = data_dict['Septic_shock'][dataset].groupby('traj')\\\n",
    "                .filter(lambda x: x.iloc[-1]['r:reward_septic_shock'] == -1)['traj'].drop_duplicates()\n",
    "\n",
    "            common_traj = set(dead_traj) & set(aki_traj) & set(ss_traj)\n",
    "            merged_traj = pd.DataFrame({'traj': list(common_traj)}).reset_index(drop=True)\n",
    "\n",
    "            for target in ['Dead_icu', 'AKI_rrt', 'Septic_shock']:\n",
    "                data = data_dict[target][dataset].copy()\n",
    "                s_col = [x for x in data if x.startswith('s:') and 'prev' not in x] + ['AKI_max_stage']\n",
    "                o_col = [col.replace('s:', '') for col in s_col if 'prev' not in col]\n",
    "                data['step'] = data.groupby('traj').cumcount()\n",
    "                data = data.groupby('traj', group_keys=False).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "                test_df_RAW = pd.read_csv(f'processed/df_{target}_RAW.csv')\n",
    "                test_df_RAW = test_df_RAW.groupby('traj', group_keys=False).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "                data[s_col] = test_df_RAW[o_col]\n",
    "                data = attach_flags_and_advise(data, data_dict, target, algorithm, threshold, dataset)\n",
    "                target_df = pd.merge(data, merged_traj[['traj']], on='traj', how='inner')\n",
    "\n",
    "                for traj_id, df_traj in target_df.groupby('traj'):\n",
    "                    if fails_filter_conditions(df_traj):\n",
    "                        merged_traj = merged_traj[merged_traj['traj'] != traj_id]\n",
    "\n",
    "            for traj_id in merged_traj['traj']:\n",
    "                if traj_id == 3388:\n",
    "                    data_list = []\n",
    "                    threshold_list = []\n",
    "                    for target in ['Dead_icu','AKI_48','Septic_shock']:\n",
    "                        data = data_dict[target][dataset].copy()\n",
    "                        s_col = [x for x in data if x.startswith('s:') and 'prev' not in x] + ['AKI_max_stage']\n",
    "                        o_col = [col.replace('s:', '') for col in s_col if 'prev' not in col]\n",
    "                        data['step'] = data.groupby('traj').cumcount()\n",
    "                        data = data.groupby('traj', group_keys=False).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "                        test_df_RAW = pd.read_csv(f'processed/df_{target}_RAW.csv')\n",
    "                        test_df_RAW = pd.merge(test_df_RAW, data['traj'].drop_duplicates(), on='traj', how='inner').reset_index(drop=True)\n",
    "                        test_df_RAW = test_df_RAW.groupby('traj', group_keys=False).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "                        print(data.shape, test_df_RAW.shape)\n",
    "                        data[s_col] = test_df_RAW[o_col]\n",
    "                        data = attach_flags_and_advise(data, data_dict, target, algorithm, threshold, dataset)\n",
    "                        df_one_traj = data[data['traj'] == traj_id]\n",
    "                        if df_one_traj.empty:\n",
    "                            continue\n",
    "                        data_list.append(df_one_traj)\n",
    "                        threshold_list.append(data_dict[target][algorithm]['_positive'][dataset]['thresholds'][threshold+'_med'])\n",
    "                        threshold_list.append(data_dict[target][algorithm]['_negative'][dataset]['thresholds'][threshold+'_med'])\n",
    "\n",
    "                    if len(data_list) < 3:\n",
    "                        continue\n",
    "\n",
    "                    if not len(data_list[0]) == len(data_list[1]) == len(data_list[2]):\n",
    "                        min_len = min(len(data_list[0]), len(data_list[1]), len(data_list[2]))\n",
    "                        data_list[0] = data_list[0].iloc[:min_len]\n",
    "                        data_list[1] = data_list[1].iloc[:min_len]\n",
    "                        data_list[2] = data_list[2].iloc[:min_len]\n",
    "\n",
    "                    df_dead = data_list[0]\n",
    "                    df_aki  = data_list[1]\n",
    "                    df_ss   = data_list[2]\n",
    "                    data_full, steps = combine_three_targets_into_array(df_dead, df_aki, df_ss, ACTION_LIST)\n",
    "                    if len(steps) == 0:\n",
    "                        continue\n",
    "                    plot_combined_heatmap(\n",
    "                        data_full,\n",
    "                        steps,\n",
    "                        df_ss=df_ss,\n",
    "                        action_list=ACTION_LIST,\n",
    "                        traj_id=f\"{traj_id}\",\n",
    "                        threshold_list=threshold_list,\n",
    "                        threshold=threshold,\n",
    "                        dataset=dataset,\n",
    "                        algorithm=algorithm\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(data_dict,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(data_dict,'temporal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_id = pd.read_csv('processed/temporal_id.csv')\n",
    "temporal_id = temporal_id[temporal_id['traj']==3388]\n",
    "temporal_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_df = pd.read_csv('processed/temporal_df_Z.csv')\n",
    "temporal_df = temporal_df[temporal_df['traj']==3388]\n",
    "temporal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohort statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"processed/df_Dead_icu_RAW.csv\")\n",
    "\n",
    "main_id = pd.concat([train_id, valid_id, test_id], axis=0)\n",
    "\n",
    "df_main = pd.merge(df, main_id[[\"traj\"]], on=\"traj\", how=\"inner\").reset_index(drop=True)\n",
    "df_temp = pd.merge(df, temporal_id[[\"traj\"]], on=\"traj\", how=\"inner\").reset_index(drop=True)\n",
    "\n",
    "N_main = df_main[\"stay_id\"].nunique()\n",
    "N_temp = df_temp[\"stay_id\"].nunique()\n",
    "\n",
    "def preprocess_fluids_vaso(data: pd.DataFrame):\n",
    "    grp = data.groupby(\"stay_id\", as_index=False)\n",
    "    df_fl = grp[\"input_4hr\"].sum()\n",
    "    df_fl[\"fluids_binary\"] = (df_fl[\"input_4hr\"] > 0).astype(int)\n",
    "    df_vas = grp[\"median_vaso\"].max()\n",
    "    df_vas[\"vaso_binary\"] = (df_vas[\"median_vaso\"] > 0).astype(int)\n",
    "    data = data.merge(df_fl[[\"stay_id\",\"fluids_binary\"]], on=\"stay_id\", how=\"left\")\n",
    "    data = data.merge(df_vas[[\"stay_id\",\"vaso_binary\"]], on=\"stay_id\", how=\"left\")\n",
    "    return data\n",
    "\n",
    "df_main = preprocess_fluids_vaso(df_main)\n",
    "df_temp = preprocess_fluids_vaso(df_temp)\n",
    "\n",
    "age_bins = [18, 30, 40, 50, 60, 70, 80, 90, np.inf]\n",
    "age_labels = [\"18-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"≥90\"]\n",
    "df_main[\"age_bin\"] = pd.cut(df_main[\"age\"], bins=age_bins, labels=age_labels, right=False)\n",
    "df_temp[\"age_bin\"] = pd.cut(df_temp[\"age\"], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "table_structure = {\n",
    "    \"Demographics\": [\n",
    "        (\"Age, years\", \"age\"),              \n",
    "        (\"Age range, years\", \"age_bin\"),   \n",
    "        (\"Gender\", \"gender\"),              \n",
    "        (\"Re-admission\", \"re_admission\")\n",
    "    ],\n",
    "    \"Physical exam findings\": [\n",
    "        (\"Temperature (\\\\textcelsius)\", \"Temperature\"),\n",
    "        (\"Weight (kg)\", \"Weight\"),\n",
    "        (\"Heart rate (bpm)\", \"Heartrate\"),\n",
    "        (\"Respiratory rate (breaths/min)\", \"Resprate\"),\n",
    "        (\"Systolic blood pressure (mmHg)\", \"Systolic_BP\"),\n",
    "        (\"Diastolic blood pressure (mmHg)\", \"Diastolic_BP\"),\n",
    "        (\"Mean arterial pressure (mmHg)\", \"Mean_BP\"),\n",
    "        (\"Fraction of inspired oxygen (\\\\%)\", \"FiO2\"),\n",
    "        (\"P/F ratio\", \"PaO2/FiO2\"),\n",
    "        (\"Glasgow Coma Scale\", \"GCS\")\n",
    "    ],\n",
    "    \"Laboratory findings\": {\n",
    "        \"Hematology\": [\n",
    "            (\"White blood cells (thousands/\\\\micro L)\", \"WBC\"),\n",
    "            (\"Platelets (thousands/\\\\micro L)\", \"Platelets\"),\n",
    "            (\"Hemoglobin (g/dL)\", \"Hemoglobin\"),\n",
    "            (\"Base Excess (mmol/L)\", \"BaseExcess\"),\n",
    "        ],\n",
    "        \"Chemistry\": [\n",
    "            (\"Sodium (mmol/L)\", \"Sodium\"),\n",
    "            (\"Potassium (mmol/L)\", \"Potassium\"),\n",
    "            (\"Chloride (mmol/L)\", \"Chloride\"),\n",
    "            (\"Bicarbonate (mmol/L)\", \"Bicarbonate\"),\n",
    "            (\"Calcium (mg/dL)\", \"Calcium\"),\n",
    "            (\"Magnesium (mg/dL)\", \"Magnesium\"),\n",
    "            (\"Blood urea nitrogen (mg/dL)\", \"BUN\"),\n",
    "            (\"Creatinine (mg/dL)\", \"SCr\"),\n",
    "            (\"Glucose (mg/dL)\", \"Glucose\"),\n",
    "            (\"SGOT (units/L)\", \"SGOT\"),\n",
    "            (\"SGPT (units/L)\", \"SGPT\"),\n",
    "            (\"Lactate (mg/dL)\", \"Lactate\"),\n",
    "            (\"Total bilirubin (mg/dL)\", \"Total_Bilirubin\")\n",
    "        ]\n",
    "    },\n",
    "    \"Outcomes\": [\n",
    "        (\"Deceased (ICU mortality)\", \"morta_icu\"),\n",
    "        (\"Vasopressors administered\", \"vaso_binary\"),\n",
    "        (\"Fluids administered\", \"fluids_binary\"),\n",
    "        (\"Ventilator used\", \"MV\")\n",
    "    ],\n",
    "    \"Severity Scores\": [\n",
    "        (\"SOFA\", \"SOFA\"),\n",
    "        (\"SIRS\", \"SIRS\"),\n",
    "        (\"Shock Index\", \"Shock_Index\")\n",
    "    ],\n",
    "    \"Coagulation\": [\n",
    "        (\"Prothrombin time (sec)\", \"PT\"),\n",
    "        (\"Partial thromboplastin time (sec)\", \"PTT\"),\n",
    "        (\"INR\", \"INR\")\n",
    "    ],\n",
    "    \"Blood gas\": [\n",
    "        (\"pH\", \"Arterial_ph\"),\n",
    "        (\"Oxygen saturation (\\\\%)\", \"SpO2\"),\n",
    "        (\"Partial pressure of O2 (mmHg)\", \"PaO2\"),\n",
    "        (\"Partial pressure of CO2 (mmHg)\", \"PaCO2\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "gender_map = {0: \"Male\", 1: \"Female\"}\n",
    "\n",
    "def summarize_single_dataset(df_local: pd.DataFrame, col_name: str, is_main: bool=True) -> str:\n",
    "    if col_name not in df_local.columns:\n",
    "        return \"N/A\"\n",
    "    series = df_local[col_name].dropna()\n",
    "    if series.empty:\n",
    "        return \"No data\"\n",
    "    n_stay = df_local[\"stay_id\"].nunique()\n",
    "    if col_name == \"age_bin\":\n",
    "        by_stay = df_local.groupby(\"stay_id\")[col_name].first()\n",
    "        counts = by_stay.value_counts(dropna=False)\n",
    "        lines = []\n",
    "        for label in age_labels:\n",
    "            if label in counts.index:\n",
    "                c = counts[label]\n",
    "                ratio = (c / n_stay)*100\n",
    "                lines.append(f\"{label} & {c} ({ratio:.1f}\\\\%)\\\\\\\\\")\n",
    "        return (\n",
    "            r\"\\begin{tabular}[l]{@{}l@{\\hspace{1em}}r@{}}\"\n",
    "            + \"\\n\".join(lines)\n",
    "            + r\"\\end{tabular}\"\n",
    "        )\n",
    "    if col_name == \"gender\":\n",
    "        by_stay = df_local.groupby(\"stay_id\")[col_name].first()\n",
    "        total = len(by_stay)\n",
    "        num_male   = (by_stay == 0).sum()\n",
    "        num_female = (by_stay == 1).sum()\n",
    "        male_pct   = (num_male / total)*100 if total>0 else 0\n",
    "        fem_pct    = (num_female / total)*100 if total>0 else 0\n",
    "        lines = []\n",
    "        lines.append(f\"Male & {num_male} ({male_pct:.1f}\\\\%)\\\\\\\\\")\n",
    "        lines.append(f\"Female & {num_female} ({fem_pct:.1f}\\\\%)\\\\\\\\\")\n",
    "        return (\n",
    "            r\"\\begin{tabular}[l]{@{}l@{\\hspace{1em}}r@{}}\"\n",
    "            + \"\\n\".join(lines)\n",
    "            + r\"\\end{tabular}\"\n",
    "        )\n",
    "    unique_vals = series.unique()\n",
    "    if len(unique_vals) == 2 and sorted(unique_vals) == [0,1] and col_name != \"gender\":\n",
    "        s_by_stay = df_local.groupby(\"stay_id\")[col_name].max()\n",
    "        c1 = (s_by_stay == 1).sum()\n",
    "        ratio1 = (c1 / n_stay)*100\n",
    "        return f\"{c1} ({ratio1:.1f}\\\\%)\"\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        med = series.median()\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        return f\"{med:.1f} ({q1:.1f}--{q3:.1f})\"\n",
    "    by_stay = df_local.groupby(\"stay_id\")[col_name].first()\n",
    "    vc = by_stay.value_counts()\n",
    "    top_cat = vc.index[0]\n",
    "    top_cnt = vc.iloc[0]\n",
    "    return f\"{top_cat} ({top_cnt} freq)\"\n",
    "\n",
    "latex_lines = []\n",
    "latex_lines.append(r\"\\begin{table}[htbp]\")\n",
    "latex_lines.append(r\"\\centering\")\n",
    "latex_lines.append(r\"\\caption{Dataset Summary}\")\n",
    "latex_lines.append(r\"\\begin{tabular}{p{0.4\\textwidth} p{0.3\\textwidth} p{0.3\\textwidth}}\")\n",
    "latex_lines.append(r\"\\hline\")\n",
    "latex_lines.append(rf\" \\textbf{{Variable}} & \\textbf{{Train+Val+Test (n={N_main})}} & \\textbf{{Temporal (n={N_temp})}} \\\\\")\n",
    "latex_lines.append(r\"\\hline\")\n",
    "\n",
    "def add_section_header(text, indent=False):\n",
    "    prefix = r\"\\quad \" if indent else \"\"\n",
    "    return rf\"\\multicolumn{{3}}{{l}}{{{prefix}\\textbf{{{text}}}}} \\\\\"\n",
    "\n",
    "def add_row(var_name, val_main, val_temp, indent=False):\n",
    "    prefix = r\"\\quad \" if indent else \"\"\n",
    "    return f\"{prefix}{var_name} & {val_main} & {val_temp} \\\\\\\\\"\n",
    "\n",
    "for section_name, items in table_structure.items():\n",
    "    if isinstance(items, dict):\n",
    "        latex_lines.append(add_section_header(section_name))\n",
    "        for subsec_name, varlist in items.items():\n",
    "            latex_lines.append(add_section_header(subsec_name, indent=True))\n",
    "            for disp_name, col_name in varlist:\n",
    "                val_main = summarize_single_dataset(df_main, col_name)\n",
    "                val_temp = summarize_single_dataset(df_temp, col_name, is_main=False)\n",
    "                latex_lines.append(add_row(disp_name, val_main, val_temp, indent=True))\n",
    "    else:\n",
    "        latex_lines.append(add_section_header(section_name))\n",
    "        for disp_name, col_name in items:\n",
    "            val_main = summarize_single_dataset(df_main, col_name)\n",
    "            val_temp = summarize_single_dataset(df_temp, col_name, is_main=False)\n",
    "            latex_lines.append(add_row(disp_name, val_main, val_temp, indent=True))\n",
    "\n",
    "latex_lines.append(r\"\\hline\")\n",
    "latex_lines.append(r\"\\end{tabular}\")\n",
    "latex_lines.append(r\"\\end{table}\")\n",
    "\n",
    "latex_code = \"\\n\".join(latex_lines)\n",
    "\n",
    "with open(\"final_summary_table.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_code)\n",
    "\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed/df_Dead_icu_RAW.csv\")\n",
    "\n",
    "main_id = pd.concat([train_id, valid_id, test_id], axis=0)\n",
    "\n",
    "df_main = pd.merge(df, main_id[[\"traj\"]], on=\"traj\", how=\"inner\").reset_index(drop=True)\n",
    "df_temp = pd.merge(df, temporal_id[[\"traj\"]], on=\"traj\", how=\"inner\").reset_index(drop=True)\n",
    "\n",
    "N_main = df_main[\"stay_id\"].nunique()\n",
    "N_temp = df_temp[\"stay_id\"].nunique()\n",
    "\n",
    "def preprocess_fluids_vaso(data: pd.DataFrame):\n",
    "    grp = data.groupby(\"stay_id\", as_index=False)\n",
    "    \n",
    "    df_fl = grp[\"input_4hr\"].sum()\n",
    "    df_fl[\"fluids_binary\"] = (df_fl[\"input_4hr\"] > 0).astype(int)\n",
    "    \n",
    "    df_vas = grp[\"median_vaso\"].max()\n",
    "    df_vas[\"vaso_binary\"] = (df_vas[\"median_vaso\"] > 0).astype(int)\n",
    "    \n",
    "    data = data.merge(df_fl[[\"stay_id\",\"fluids_binary\"]], on=\"stay_id\", how=\"left\")\n",
    "    data = data.merge(df_vas[[\"stay_id\",\"vaso_binary\"]], on=\"stay_id\", how=\"left\")\n",
    "    return data\n",
    "\n",
    "df_main = preprocess_fluids_vaso(df_main)\n",
    "df_temp = preprocess_fluids_vaso(df_temp)\n",
    "\n",
    "age_bins = [18, 30, 40, 50, 60, 70, 80, 90, np.inf]\n",
    "age_labels = [\"18-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"≥90\"]\n",
    "\n",
    "df_main[\"age_bin\"] = pd.cut(df_main[\"age\"], bins=age_bins, labels=age_labels, right=False)\n",
    "df_temp[\"age_bin\"] = pd.cut(df_temp[\"age\"], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "def summarize_variable(df_m: pd.DataFrame, df_t: pd.DataFrame, col_name: str):\n",
    "    main_str = compute_stat_string(df_m, col_name)\n",
    "    temp_str = compute_stat_string(df_t, col_name)\n",
    "    return f\"Main: {main_str}\\\\quad Temp: {temp_str}\"\n",
    "\n",
    "def compute_stat_string(df_local: pd.DataFrame, col_name: str) -> str:\n",
    "    if col_name not in df_local.columns:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    s = df_local[col_name].dropna()\n",
    "    if s.empty:\n",
    "        return \"No data\"\n",
    "    \n",
    "    n_stay = df_local[\"stay_id\"].nunique()\n",
    "    unique_vals = sorted(s.unique())\n",
    "    \n",
    "    if col_name == \"gender\":\n",
    "        by_stay = df_local.groupby(\"stay_id\")[col_name].first()\n",
    "        total = len(by_stay)\n",
    "        nm = (by_stay==0).sum()\n",
    "        nf = (by_stay==1).sum()\n",
    "        pm = (nm/total)*100 if total>0 else 0\n",
    "        pf = (nf/total)*100 if total>0 else 0\n",
    "        return f\"Male {nm} ({pm:.1f}%), Female {nf} ({pf:.1f}%)\"\n",
    "    \n",
    "    if col_name == \"age_bin\":\n",
    "        by_stay = df_local.groupby(\"stay_id\")[col_name].first()\n",
    "        counts = by_stay.value_counts()\n",
    "        total = len(by_stay)\n",
    "        lines = []\n",
    "        for lab in age_labels:\n",
    "            c = counts.get(lab, 0)\n",
    "            ratio = (c/total)*100 if total>0 else 0\n",
    "            lines.append(f\"{lab}: {c} ({ratio:.1f}%)\")\n",
    "        return \"; \".join(lines)\n",
    "    \n",
    "    if len(unique_vals)==2 and unique_vals==[0,1] and col_name!=\"gender\":\n",
    "        st = df_local.groupby(\"stay_id\")[col_name].max()\n",
    "        c1 = (st==1).sum()\n",
    "        ratio1 = (c1/len(st))*100 if len(st)>0 else 0\n",
    "        return f\"{c1} ({ratio1:.1f}%)\"\n",
    "    \n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        med = s.median()\n",
    "        q1  = s.quantile(0.25)\n",
    "        q3  = s.quantile(0.75)\n",
    "        return f\"{med:.1f} ({q1:.1f}--{q3:.1f})\"\n",
    "    \n",
    "\n",
    "    by_stay = df_local.groupby(\"stay_id\")[col_name].first()\n",
    "    vc = by_stay.value_counts()\n",
    "    top_cat = vc.index[0]\n",
    "    top_cnt = vc.iloc[0]\n",
    "    return f\"{top_cat} ({top_cnt} freq)\"\n",
    "\n",
    "latex_lines = []\n",
    "\n",
    "latex_lines.append(r\"\\begin{table}[htbp]\")\n",
    "latex_lines.append(r\"\\centering\")\n",
    "latex_lines.append(r\"\\begin{tabular}{l}\")\n",
    "latex_lines.append(r\"\\hline\")\n",
    "latex_lines.append(r\"\\\\[-1em]\")\n",
    "\n",
    "latex_lines.append(f\"Train+Val+Test (n={N_main}), Temporal (n={N_temp})\\\\\\\\\")\n",
    "latex_lines.append(r\"\\\\[-1em]\\hline\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\textbf{Demographics}\\\\\")\n",
    "latex_lines.append(r\"\\quad Age, years\\\\\")\n",
    "stat_age_years = summarize_variable(df_main, df_temp, \"age\")  \n",
    "latex_lines.append(r\"\\quad\\quad \" + stat_age_years + r\"\\\\\")  \n",
    "\n",
    "latex_lines.append(r\"\\quad Age range, years\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad 18-29\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad 30-39\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad 40-49\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad 50-59\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad 60-69\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad 70-79\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad 80-89\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad ≥90\\\\\")\n",
    "\n",
    "stat_age_bin = summarize_variable(df_main, df_temp, \"age_bin\")\n",
    "latex_lines.append(r\"\\quad\\quad \" + stat_age_bin + r\"\\\\\")  \n",
    "\n",
    "latex_lines.append(r\"\\quad Gender\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad Male\\\\\")\n",
    "latex_lines.append(r\"\\quad\\quad Female\\\\\")\n",
    "\n",
    "stat_gender = summarize_variable(df_main, df_temp, \"gender\")\n",
    "latex_lines.append(r\"\\quad\\quad \" + stat_gender + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\quad Re-admission\\\\\")\n",
    "stat_readm = summarize_variable(df_main, df_temp, \"re_admission\")\n",
    "latex_lines.append(r\"\\quad\\quad \" + stat_readm + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\textbf{Physical exam findings}\\\\\")\n",
    "\n",
    "pe_vars = [\n",
    "    (\"Temperature (\\\\textcelsius)\", \"Temperature\"),\n",
    "    (\"Weight (kg)\", \"Weight\"),\n",
    "    (\"Heart rate (bpm)\", \"Heartrate\"),\n",
    "    (\"Respiratory rate (breaths/min)\", \"Resprate\"),\n",
    "    (\"Systolic blood pressure (mmHg)\", \"Systolic_BP\"),\n",
    "    (\"Diastolic blood pressure (mmHg)\", \"Diastolic_BP\"),\n",
    "    (\"Mean arterial pressure (mmHg)\", \"Mean_BP\"),\n",
    "    (\"Fraction of inspired oxygen (\\\\%)\", \"FiO2\"),\n",
    "    (\"P/F ratio\", \"PaO2/FiO2\"),\n",
    "    (\"Glasgow Coma Scale\", \"GCS\")\n",
    "]\n",
    "for disp, col in pe_vars:\n",
    "    latex_lines.append(r\"\\quad \" + disp + r\"\\\\\")\n",
    "    stat_val = summarize_variable(df_main, df_temp, col)\n",
    "    latex_lines.append(r\"\\quad\\quad \" + stat_val + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\textbf{Laboratory findings}\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\quad \\textbf{Hematology}\\\\\")\n",
    "hema_vars = [\n",
    "    (\"White blood cells (thousands/\\\\micro L)\", \"WBC\"),\n",
    "    (\"Platelets (thousands/\\\\micro L)\", \"Platelets\"),\n",
    "    (\"Hemoglobin (g/dL)\", \"Hemoglobin\"),\n",
    "    (\"Base Excess (mmol/L)\", \"BaseExcess\")\n",
    "]\n",
    "for disp, col in hema_vars:\n",
    "    latex_lines.append(r\"\\quad\\quad \" + disp + r\"\\\\\")\n",
    "    stat_val = summarize_variable(df_main, df_temp, col)\n",
    "    latex_lines.append(r\"\\quad\\quad\\quad \" + stat_val + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\quad \\textbf{Chemistry}\\\\\")\n",
    "chem_vars = [\n",
    "    (\"Sodium (mmol/L)\", \"Sodium\"),\n",
    "    (\"Potassium (mmol/L)\", \"Potassium\"),\n",
    "    (\"Chloride (mmol/L)\", \"Chloride\"),\n",
    "    (\"Bicarbonate (mmol/L)\", \"Bicarbonate\"),\n",
    "    (\"Calcium (mg/dL)\", \"Calcium\"),\n",
    "    (\"Magnesium (mg/dL)\", \"Magnesium\"),\n",
    "    (\"Blood urea nitrogen (mg/dL)\", \"BUN\"),\n",
    "    (\"Creatinine (mg/dL)\", \"SCr\"),\n",
    "    (\"Glucose (mg/dL)\", \"Glucose\"),\n",
    "    (\"SGOT (units/L)\", \"SGOT\"),\n",
    "    (\"SGPT (units/L)\", \"SGPT\"),\n",
    "    (\"Lactate (mg/dL)\", \"Lactate\"),\n",
    "    (\"Total bilirubin (mg/dL)\", \"Total_Bilirubin\")\n",
    "]\n",
    "for disp, col in chem_vars:\n",
    "    latex_lines.append(r\"\\quad\\quad \" + disp + r\"\\\\\")\n",
    "    stat_val = summarize_variable(df_main, df_temp, col)\n",
    "    latex_lines.append(r\"\\quad\\quad\\quad \" + stat_val + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\textbf{Outcomes}\\\\\")\n",
    "\n",
    "out_vars = [\n",
    "    (\"Deceased (ICU mortality)\", \"morta_icu\"),\n",
    "    (\"Vasopressors administered\", \"vaso_binary\"),\n",
    "    (\"Fluids administered\", \"fluids_binary\"),\n",
    "    (\"Ventilator used\", \"MV\")\n",
    "]\n",
    "for disp, col in out_vars:\n",
    "    latex_lines.append(r\"\\quad \" + disp + r\"\\\\\")\n",
    "    stat_val = summarize_variable(df_main, df_temp, col)\n",
    "    latex_lines.append(r\"\\quad\\quad \" + stat_val + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\textbf{Severity Scores}\\\\\")\n",
    "sev_vars = [\n",
    "    (\"SOFA\", \"SOFA\"),\n",
    "    (\"SIRS\", \"SIRS\"),\n",
    "    (\"Shock Index\", \"Shock_Index\")\n",
    "]\n",
    "for disp, col in sev_vars:\n",
    "    latex_lines.append(r\"\\quad \" + disp + r\"\\\\\")\n",
    "    stat_val = summarize_variable(df_main, df_temp, col)\n",
    "    latex_lines.append(r\"\\quad\\quad \" + stat_val + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\textbf{Coagulation}\\\\\")\n",
    "coag_vars = [\n",
    "    (\"Prothrombin time (sec)\", \"PT\"),\n",
    "    (\"Partial thromboplastin time (sec)\", \"PTT\"),\n",
    "    (\"INR\", \"INR\")\n",
    "]\n",
    "for disp, col in coag_vars:\n",
    "    latex_lines.append(r\"\\quad \" + disp + r\"\\\\\")\n",
    "    stat_val = summarize_variable(df_main, df_temp, col)\n",
    "    latex_lines.append(r\"\\quad\\quad \" + stat_val + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\textbf{Blood gas}\\\\\")\n",
    "bg_vars = [\n",
    "    (\"pH\", \"Arterial_ph\"),\n",
    "    (\"Oxygen saturation (\\\\%)\", \"SpO2\"),\n",
    "    (\"Partial pressure of O2 (mmHg)\", \"PaO2\"),\n",
    "    (\"Partial pressure of CO2 (mmHg)\", \"PaCO2\")\n",
    "]\n",
    "for disp, col in bg_vars:\n",
    "    latex_lines.append(r\"\\quad \" + disp + r\"\\\\\")\n",
    "    stat_val = summarize_variable(df_main, df_temp, col)\n",
    "    latex_lines.append(r\"\\quad\\quad \" + stat_val + r\"\\\\\")\n",
    "\n",
    "latex_lines.append(r\"\\\\[-0.5em]\")\n",
    "\n",
    "latex_lines.append(r\"\\hline\")\n",
    "latex_lines.append(r\"\\end{tabular}\")\n",
    "latex_lines.append(r\"\\end{table}\")\n",
    "\n",
    "latex_code = \"\\n\".join(latex_lines)\n",
    "\n",
    "with open(\"final_structure.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_code)\n",
    "\n",
    "print(latex_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medclap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
